{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
    "\n",
    "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
    "\n",
    "Now we're going to cover another type of transfer learning: fine-tuning.\n",
    "\n",
    "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
    "\n",
    "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ layers of a pre-trained model (where the '+' indicates that many or all of the layers could be trained).\n",
    "\n",
    "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)\n",
    "*Feature extraction transfer learning vs. fine-tuning transfer learning. The main difference between the two is that in fine-tuning, more layers of the pre-trained model get unfrozen and tuned on custom data. This fine-tuning usually takes more data than feature extraction to be effective.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What we're going to cover\n",
    "\n",
    "We're going to go through the follow with TensorFlow:\n",
    "\n",
    "- Introduce fine-tuning, a type of transfer learning to modify a pre-trained model to be more suited to your data\n",
    "- Using the Keras Functional API (a differnt way to build models in Keras)\n",
    "- Using a smaller dataset to experiment faster (e.g. 1-10% of training samples of 10 classes of food)\n",
    "- Data augmentation (how to make your training dataset more diverse without adding more data)\n",
    "- Running a series of modelling experiments on our Food Vision data\n",
    "  - **Model 0**: a transfer learning model using the Keras Functional API\n",
    "  - **Model 1**: a feature extraction transfer learning model on 1% of the data with data augmentation\n",
    "  - **Model 2**: a feature extraction transfer learning model on 10% of the data with data augmentation\n",
    "  - **Model 3**: a fine-tuned transfer learning model on 10% of the data\n",
    "  - **Model 4**: a fine-tuned transfer learning model on 100% of the data\n",
    "- Introduce the ModelCheckpoint callback to save intermediate training results\n",
    "- Compare model experiments results using TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 15 07:04:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    On  |   00000000:65:00.0 Off |                  N/A |\n",
      "| N/A   36C    P8              2W /   80W |       0MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2173      C   /python3.12                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Are we using a GPU?\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating helper functions\n",
    "\n",
    "Throughout your machine learning experiments, you'll likely come across snippets of code you want to use over and over again.\n",
    "\n",
    "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
    "\n",
    "You could recreate these functions over and over again.\n",
    "\n",
    "But as you might've guessed, rewritting the same functions becomes tedious.\n",
    "\n",
    "One of the solutions is to store them in a helper script such as [`helper_functions.py`](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py). And then import the necesary functionality when you need it.\n",
    "\n",
    "For example, you might write:\n",
    "\n",
    "```\n",
    "from helper_functions import plot_loss_curves\n",
    "\n",
    "...\n",
    "\n",
    "plot_loss_curves(history)\n",
    "```\n",
    "\n",
    "Let's see what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get helper_functions.py script from course GitHub\n",
    "# !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "# Import helper functions we're going to use\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Food Classes: Working with less data\n",
    "\n",
    "We saw in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb) that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
    "\n",
    "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications) module as well as how to fine-tune them to our own custom dataset.\n",
    "\n",
    "We'll also practice using a new but similar dataloader function to what we've used before, [`image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) which is part of the [`tf.keras.utils`](https://www.tensorflow.org/api_docs/python/tf/keras/utils) module.\n",
    "\n",
    "Finally, we'll also be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API.\n",
    "\n",
    "We'll explore each of these in more detail as we go.\n",
    "\n",
    "Let's start by downloading some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10% of the data of the 10 classes\n",
    "# Download data (Skip, load the data locally)\n",
    "\n",
    "# !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
    "\n",
    "# unzip_data(\"10_food_classes_10_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'data/image_data/10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in 'data/image_data/10_food_classes_10_percent/test'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/chicken_curry'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/chicken_wings'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/fried_rice'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/grilled_salmon'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/hamburger'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/ice_cream'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/pizza'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/ramen'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/steak'.\n",
      "There are 0 directories and 250 images in 'data/image_data/10_food_classes_10_percent/test/sushi'.\n",
      "There are 10 directories and 0 images in 'data/image_data/10_food_classes_10_percent/train'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/chicken_curry'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/chicken_wings'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/fried_rice'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/grilled_salmon'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/hamburger'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/ice_cream'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/pizza'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/ramen'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/steak'.\n",
      "There are 0 directories and 75 images in 'data/image_data/10_food_classes_10_percent/train/sushi'.\n"
     ]
    }
   ],
   "source": [
    "food_classes_dir = \"data/image_data/10_food_classes_10_percent\"\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "walk_through_dir(food_classes_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each of the training directories contain 75 images and each of the testing directories contain 250 images.\n",
    "\n",
    "Let's define our training and test filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = food_classes_dir + \"/train/\"\n",
    "test_dir = food_classes_dir + \"/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got some image data, we need a way of loading it into a TensorFlow compatible format.\n",
    "\n",
    "Previously, we've used the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class.\n",
    "\n",
    "However, as of August 2023, this class is deprecated and isn't recommended for future usage (it's too slow).\n",
    "\n",
    "Because of this, we'll move onto using `tf.keras.utils.image_dataset_from_directory()`.\n",
    "\n",
    "This method expects image data in the following file format:\n",
    "\n",
    "```\n",
    "Example of file structure\n",
    "\n",
    "10_food_classes_10_percent <- top level folder\n",
    "└───train <- training images\n",
    "│   └───pizza\n",
    "│   │   │   1008104.jpg\n",
    "│   │   │   1638227.jpg\n",
    "│   │   │   ...      \n",
    "│   └───steak\n",
    "│       │   1000205.jpg\n",
    "│       │   1647351.jpg\n",
    "│       │   ...\n",
    "│   \n",
    "└───test <- testing images\n",
    "│   └───pizza\n",
    "│   │   │   1001116.jpg\n",
    "│   │   │   1507019.jpg\n",
    "│   │   │   ...      \n",
    "│   └───steak\n",
    "│       │   100274.jpg\n",
    "│       │   1653815.jpg\n",
    "│       │   ...    \n",
    "```\n",
    "\n",
    "One of the main benefits of using [`tf.keras.prepreprocessing.image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) rather than `ImageDataGenerator` is that it creates a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) object rather than a generator.\n",
    "\n",
    "The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data inputs\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)  # define image size\n",
    "\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    label_mode=\"categorical\",  # what type are the labels?\n",
    "    batch_size=32)  # batch_size is 32 by default, this is generally a good number\n",
    "\n",
    "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                           image_size=IMG_SIZE,\n",
    "                                                                           label_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! Looks like our dataloaders have found the correct number of images for each dataset.\n",
    "\n",
    "For now, the main parameters we're concerned about in the `image_dataset_from_directory()` funtion are:\n",
    "* `directory` - the filepath of the target directory we're loading images in from.\n",
    "* `image_size` - the target size of the images we're going to load in (height, width).\n",
    "* `batch_size` - the batch size of the images we're going to load in. For example if the `batch_size` is 32 (the default), batches of 32 images and labels at a time will be passed to the model.\n",
    "\n",
    "There are more we could play around with if we needed to [in the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory).\n",
    "\n",
    "If we check the training data datatype we should see it as a `BatchDataset` with shapes relating to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the training data datatype\n",
    "train_data_10_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output:\n",
    "\n",
    "* `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channels (red, green, blue).\n",
    "* `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
    "* Both image tensors and labels are of the datatype `tf.float32`.\n",
    "\n",
    "The `batch_size` is `None` due to it only being used during model training. You can think of `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
    "\n",
    "Another benefit of using the `tf.data.Dataset` API are the assosciated methods which come with it.\n",
    "\n",
    "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chicken_curry',\n",
       " 'chicken_wings',\n",
       " 'fried_rice',\n",
       " 'grilled_salmon',\n",
       " 'hamburger',\n",
       " 'ice_cream',\n",
       " 'pizza',\n",
       " 'ramen',\n",
       " 'steak',\n",
       " 'sushi']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the class names of our dataset\n",
    "train_data_10_percent.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we wanted to see an example batch of data, we could use the `take()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1.6092857e+02 1.6092857e+02 1.6964285e+02]\n",
      "   [1.6321429e+02 1.6321429e+02 1.7512245e+02]\n",
      "   [1.6485715e+02 1.6442346e+02 1.7886736e+02]\n",
      "   ...\n",
      "   [1.7407146e+02 1.5649998e+02 1.4271425e+02]\n",
      "   [1.7431123e+02 1.5631123e+02 1.4231123e+02]\n",
      "   [1.7541328e+02 1.5741328e+02 1.4341328e+02]]\n",
      "\n",
      "  [[1.6750000e+02 1.6742857e+02 1.6971428e+02]\n",
      "   [1.6978572e+02 1.6878572e+02 1.7400000e+02]\n",
      "   [1.7105612e+02 1.7105612e+02 1.7973979e+02]\n",
      "   ...\n",
      "   [1.7885715e+02 1.6085715e+02 1.4728568e+02]\n",
      "   [1.7886224e+02 1.6086224e+02 1.4686224e+02]\n",
      "   [1.7988266e+02 1.6288266e+02 1.4688266e+02]]\n",
      "\n",
      "  [[1.7341837e+02 1.7148979e+02 1.6506633e+02]\n",
      "   [1.7564285e+02 1.7403062e+02 1.6941327e+02]\n",
      "   [1.7664285e+02 1.7485713e+02 1.7495407e+02]\n",
      "   ...\n",
      "   [1.8059692e+02 1.6276529e+02 1.4842854e+02]\n",
      "   [1.8142857e+02 1.6400000e+02 1.4818367e+02]\n",
      "   [1.8321428e+02 1.6421428e+02 1.4878572e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.9428564e+02 1.3856633e+02 7.5010170e+01]\n",
      "   [1.9785715e+02 1.4285715e+02 7.7928574e+01]\n",
      "   [2.0200002e+02 1.4804596e+02 7.8551010e+01]\n",
      "   ...\n",
      "   [1.9978574e+02 1.8178574e+02 1.6778574e+02]\n",
      "   [1.9980104e+02 1.8180104e+02 1.6780104e+02]\n",
      "   [2.0000000e+02 1.8200000e+02 1.6800000e+02]]\n",
      "\n",
      "  [[1.9338268e+02 1.3842860e+02 7.1954071e+01]\n",
      "   [1.9892860e+02 1.4486227e+02 7.4928574e+01]\n",
      "   [2.0355615e+02 1.5155615e+02 7.8000000e+01]\n",
      "   ...\n",
      "   [2.0005614e+02 1.8205614e+02 1.6805614e+02]\n",
      "   [1.9999490e+02 1.8199490e+02 1.6799490e+02]\n",
      "   [1.9859689e+02 1.8059689e+02 1.6659689e+02]]\n",
      "\n",
      "  [[1.9641328e+02 1.4241328e+02 7.2413277e+01]\n",
      "   [2.0214290e+02 1.4814290e+02 7.5571396e+01]\n",
      "   [2.0514290e+02 1.5378575e+02 7.7571465e+01]\n",
      "   ...\n",
      "   [2.0078574e+02 1.8278574e+02 1.6878574e+02]\n",
      "   [2.0085712e+02 1.8285712e+02 1.6885712e+02]\n",
      "   [1.9764282e+02 1.7964282e+02 1.6564282e+02]]]\n",
      "\n",
      "\n",
      " [[[1.8220345e+02 1.8420345e+02 1.9920345e+02]\n",
      "   [2.0691040e+02 2.0891040e+02 2.2391040e+02]\n",
      "   [1.6876021e+02 1.7240306e+02 1.8676021e+02]\n",
      "   ...\n",
      "   [1.9990111e+02 2.0690111e+02 2.1690111e+02]\n",
      "   [1.9839886e+02 2.0539886e+02 2.1539886e+02]\n",
      "   [1.8709262e+02 1.9409262e+02 2.0409262e+02]]\n",
      "\n",
      "  [[1.8278444e+02 1.8503891e+02 2.0003891e+02]\n",
      "   [2.0664157e+02 2.0889604e+02 2.2389604e+02]\n",
      "   [1.6727806e+02 1.7092091e+02 1.8538712e+02]\n",
      "   ...\n",
      "   [2.0500000e+02 2.1200000e+02 2.2200000e+02]\n",
      "   [2.0658542e+02 2.1358542e+02 2.2358542e+02]\n",
      "   [1.9835254e+02 2.0535254e+02 2.1535254e+02]]\n",
      "\n",
      "  [[1.8269260e+02 1.8569260e+02 2.0069260e+02]\n",
      "   [2.0676180e+02 2.0976180e+02 2.2476180e+02]\n",
      "   [1.6460651e+02 1.6924904e+02 1.8370154e+02]\n",
      "   ...\n",
      "   [2.0448502e+02 2.1148502e+02 2.2148502e+02]\n",
      "   [2.0814095e+02 2.1514095e+02 2.2514095e+02]\n",
      "   [2.0429836e+02 2.1129836e+02 2.2129836e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.0722290e+02 2.1122290e+02 2.1222290e+02]\n",
      "   [2.0500000e+02 2.0900000e+02 2.1000000e+02]\n",
      "   [1.9845247e+02 2.0245247e+02 2.0345247e+02]\n",
      "   ...\n",
      "   [1.9612338e+02 2.0012338e+02 1.9955191e+02]\n",
      "   [1.9600000e+02 2.0000000e+02 1.9900000e+02]\n",
      "   [1.9657587e+02 2.0057587e+02 1.9957587e+02]]\n",
      "\n",
      "  [[2.0707143e+02 2.1107143e+02 2.1207143e+02]\n",
      "   [2.0500000e+02 2.0900000e+02 2.1000000e+02]\n",
      "   [1.9953123e+02 2.0353123e+02 2.0453123e+02]\n",
      "   ...\n",
      "   [1.9621426e+02 2.0021426e+02 1.9964279e+02]\n",
      "   [1.9600000e+02 2.0000000e+02 1.9900000e+02]\n",
      "   [1.9700000e+02 2.0100000e+02 2.0000000e+02]]\n",
      "\n",
      "  [[2.0733290e+02 2.1133290e+02 2.1233290e+02]\n",
      "   [2.0506537e+02 2.0906537e+02 2.1006537e+02]\n",
      "   [2.0122383e+02 2.0522383e+02 2.0622383e+02]\n",
      "   ...\n",
      "   [1.9621426e+02 2.0021426e+02 1.9964279e+02]\n",
      "   [1.9515022e+02 1.9915022e+02 1.9815022e+02]\n",
      "   [1.9700000e+02 2.0100000e+02 2.0000000e+02]]]\n",
      "\n",
      "\n",
      " [[[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.9309328e+02 1.6598964e+02 1.5704146e+02]\n",
      "   [1.9470473e+02 1.6755963e+02 1.5655963e+02]\n",
      "   [2.0042714e+02 1.7044228e+02 1.5677057e+02]\n",
      "   ...\n",
      "   [2.3841965e+02 1.4747752e+02 1.5423431e+02]\n",
      "   [2.3101172e+02 1.5900290e+02 1.5993367e+02]\n",
      "   [2.2087184e+02 1.6262694e+02 1.5850812e+02]]\n",
      "\n",
      "  [[1.9423358e+02 1.6580421e+02 1.5744116e+02]\n",
      "   [1.9972768e+02 1.7085715e+02 1.6029242e+02]\n",
      "   [2.0387898e+02 1.7169244e+02 1.5878572e+02]\n",
      "   ...\n",
      "   [2.3456473e+02 1.4159514e+02 1.4936568e+02]\n",
      "   [2.2734116e+02 1.4923889e+02 1.5192619e+02]\n",
      "   [2.2457050e+02 1.5840784e+02 1.5715475e+02]]\n",
      "\n",
      "  [[1.9790178e+02 1.6590195e+02 1.5769467e+02]\n",
      "   [2.0018352e+02 1.6868080e+02 1.5805899e+02]\n",
      "   [2.0301546e+02 1.6913600e+02 1.5660938e+02]\n",
      "   ...\n",
      "   [2.3353369e+02 1.3853662e+02 1.4675089e+02]\n",
      "   [2.2898163e+02 1.4222850e+02 1.4758833e+02]\n",
      "   [2.2779698e+02 1.4873865e+02 1.5181693e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5963585e+02 8.6635849e+01 7.9086777e+01]\n",
      "   [1.5670586e+02 8.5882248e+01 7.7607712e+01]\n",
      "   [1.5400000e+02 8.4000000e+01 7.5450928e+01]\n",
      "   ...\n",
      "   [2.0579016e+02 1.4637558e+02 1.4676921e+02]\n",
      "   [2.1324783e+02 1.5354198e+02 1.5403221e+02]\n",
      "   [2.0690741e+02 1.4745648e+02 1.4692282e+02]]\n",
      "\n",
      "  [[1.5963026e+02 8.7194984e+01 7.6500801e+01]\n",
      "   [1.5540417e+02 8.4017693e+01 7.4372284e+01]\n",
      "   [1.5750937e+02 8.7509384e+01 7.7509384e+01]\n",
      "   ...\n",
      "   [2.1203885e+02 1.5473303e+02 1.5705576e+02]\n",
      "   [2.1086972e+02 1.5194116e+02 1.5372684e+02]\n",
      "   [2.0727467e+02 1.4927467e+02 1.4807297e+02]]\n",
      "\n",
      "  [[1.6564781e+02 9.3647812e+01 7.9938034e+01]\n",
      "   [1.6660207e+02 9.6642403e+01 8.4728699e+01]\n",
      "   [1.6662596e+02 9.8335732e+01 8.7847229e+01]\n",
      "   ...\n",
      "   [2.2351468e+02 1.6836957e+02 1.7265082e+02]\n",
      "   [2.2072861e+02 1.6418149e+02 1.6517334e+02]\n",
      "   [2.0600000e+02 1.4714511e+02 1.4352861e+02]]]\n",
      "\n",
      "\n",
      " [[[3.0000000e+00 2.0000000e+00 1.0000000e+01]\n",
      "   [3.0000000e+00 2.0000000e+00 8.0000000e+00]\n",
      "   [7.8571415e-01 0.0000000e+00 5.5714283e+00]\n",
      "   ...\n",
      "   [2.2647995e+01 9.2092352e+00 9.2092352e+00]\n",
      "   [2.6096943e+01 1.4903082e+01 1.4500013e+01]\n",
      "   [2.6785713e+01 1.6785713e+01 1.5785714e+01]]\n",
      "\n",
      "  [[3.0000000e+00 2.0000000e+00 1.0000000e+01]\n",
      "   [3.0000000e+00 2.0000000e+00 8.0000000e+00]\n",
      "   [7.8571415e-01 0.0000000e+00 5.5714283e+00]\n",
      "   ...\n",
      "   [2.0255083e+01 5.8571644e+00 5.0561237e+00]\n",
      "   [1.8142843e+01 7.1428432e+00 5.1428432e+00]\n",
      "   [1.6857107e+01 5.8571072e+00 3.8571072e+00]]\n",
      "\n",
      "  [[3.0000000e+00 1.7857141e+00 1.0428572e+01]\n",
      "   [3.0000000e+00 2.0000000e+00 1.0000000e+01]\n",
      "   [7.8571415e-01 0.0000000e+00 5.7857141e+00]\n",
      "   ...\n",
      "   [1.8357143e+01 4.7857141e+00 5.2142859e+00]\n",
      "   [1.8015282e+01 4.6428699e+00 3.7857141e+00]\n",
      "   [1.6357143e+01 5.5714283e+00 3.7857141e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.4207652e+02 1.4564799e+02 2.1964799e+02]\n",
      "   [1.4028569e+02 1.4385716e+02 2.1785716e+02]\n",
      "   [1.4181119e+02 1.4278572e+02 2.1778574e+02]\n",
      "   ...\n",
      "   [9.7336708e+01 1.4707654e+02 1.9569392e+02]\n",
      "   [1.0057135e+02 1.4892856e+02 2.0569893e+02]\n",
      "   [1.1150000e+02 1.5985721e+02 2.1899490e+02]]\n",
      "\n",
      "  [[1.4102551e+02 1.4702551e+02 2.2302551e+02]\n",
      "   [1.3914287e+02 1.4514287e+02 2.2114287e+02]\n",
      "   [1.4122958e+02 1.4401530e+02 2.2101530e+02]\n",
      "   ...\n",
      "   [1.0057147e+02 1.5250003e+02 2.0285724e+02]\n",
      "   [9.9489883e+01 1.4941844e+02 2.0263277e+02]\n",
      "   [1.0413786e+02 1.5313786e+02 2.0913786e+02]]\n",
      "\n",
      "  [[1.4100000e+02 1.4900000e+02 2.2400000e+02]\n",
      "   [1.3940309e+02 1.4740309e+02 2.2240309e+02]\n",
      "   [1.4165300e+02 1.4528064e+02 2.2200000e+02]\n",
      "   ...\n",
      "   [1.1020927e+02 1.6114288e+02 2.1891844e+02]\n",
      "   [1.0797457e+02 1.5897458e+02 2.1588272e+02]\n",
      "   [1.0600000e+02 1.5500000e+02 2.1100000e+02]]]\n",
      "\n",
      "\n",
      " [[[2.4928572e+02 2.3728572e+02 2.1528572e+02]\n",
      "   [2.4964285e+02 2.3764285e+02 2.1564285e+02]\n",
      "   [2.5071939e+02 2.3850511e+02 2.1714796e+02]\n",
      "   ...\n",
      "   [1.0273460e+02 5.2454086e+01 2.8245005e+01]\n",
      "   [8.2831627e+01 4.3545967e+01 2.5091906e+01]\n",
      "   [7.2576538e+01 3.8949078e+01 2.4505178e+01]]\n",
      "\n",
      "  [[2.5133163e+02 2.4033163e+02 2.2033163e+02]\n",
      "   [2.5092857e+02 2.3992857e+02 2.1992857e+02]\n",
      "   [2.4980103e+02 2.3880103e+02 2.2068878e+02]\n",
      "   ...\n",
      "   [1.1973976e+02 5.7326576e+01 1.0112398e+01]\n",
      "   [9.3760384e+01 4.1469616e+01 2.1992083e+00]\n",
      "   [1.0526497e+02 5.6550751e+01 2.0739553e+01]]\n",
      "\n",
      "  [[2.5300000e+02 2.4164285e+02 2.2585715e+02]\n",
      "   [2.5205612e+02 2.4069897e+02 2.2491327e+02]\n",
      "   [2.5100000e+02 2.3964285e+02 2.2385715e+02]\n",
      "   ...\n",
      "   [1.6251010e+02 8.6933624e+01 1.4816301e+01]\n",
      "   [1.4843883e+02 7.5581688e+01 1.0653144e+01]\n",
      "   [1.3810181e+02 6.6958954e+01 6.3212028e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[7.5270454e+01 1.8709213e+01 4.4183612e+00]\n",
      "   [6.7586731e+01 1.3428570e+01 1.3877505e+00]\n",
      "   [6.2566334e+01 1.2948993e+01 2.6377201e+00]\n",
      "   ...\n",
      "   [2.4655098e+02 2.3278574e+02 2.0083165e+02]\n",
      "   [2.4234184e+02 2.2812758e+02 1.9912758e+02]\n",
      "   [2.4492348e+02 2.3049495e+02 2.0213774e+02]]\n",
      "\n",
      "  [[8.2214401e+01 2.2005194e+01 8.4082642e+00]\n",
      "   [7.0438805e+01 1.4158166e+01 1.0203985e+00]\n",
      "   [7.1800949e+01 1.8627472e+01 6.8417563e+00]\n",
      "   ...\n",
      "   [2.4471429e+02 2.2971429e+02 1.9842865e+02]\n",
      "   [2.4306123e+02 2.2906123e+02 2.0206635e+02]\n",
      "   [2.4559698e+02 2.3159698e+02 2.0466843e+02]]\n",
      "\n",
      "  [[8.2775009e+01 2.0775005e+01 7.1526918e+00]\n",
      "   [7.0203964e+01 1.2132533e+01 1.8366280e-01]\n",
      "   [6.3301147e+01 9.5766430e+00 3.0615255e-01]\n",
      "   ...\n",
      "   [2.4370921e+02 2.2749495e+02 2.0177559e+02]\n",
      "   [2.4571423e+02 2.2971423e+02 2.0552043e+02]\n",
      "   [2.4171436e+02 2.2671436e+02 2.0442871e+02]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 07:04:05.921286: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# See an example batch of data\n",
    "for images, labels in train_data_10_percent.take(1):\n",
    "    print(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
