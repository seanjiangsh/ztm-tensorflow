{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TensorFlow Fundamentals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV-gg09CnRGY"
      },
      "source": [
        "In this notebook, we're going to cover some of the most fundamental concepts of tensors using TensorFlow\n",
        "\n",
        "More specifically, we are going to cover:\n",
        "* Introducion to tensors\n",
        "* Getting information from tensors\n",
        "* Manipulating tensors\n",
        "* Tensors & NumPy\n",
        "* Using @tf.function (a way to speed up your regular Python functions)\n",
        "* Using GPUs with TensorFlow (or TPUs)\n",
        "* Exercises to try for yourself!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ1AA_mUn9Pr"
      },
      "source": [
        "## Introduction to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBJkLs_5lOpm",
        "outputId": "f577f0a4-8489-445a-f439-8b8015705105"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-11 09:08:47.378511: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-11 09:08:52.155438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-11 09:08:53.890011: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-11 09:08:54.349964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-11 09:08:57.827476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-11 09:09:20.346857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1m_LiERqY61"
      },
      "source": [
        "### Creating tensors with tf.constant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbtrIh3coIVa",
        "outputId": "cbb920e3-d360-4f3f-d6f2-5a065c582ed7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1728608994.977588    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728608999.831057    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728608999.831117    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728608999.846399    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728608999.846478    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728608999.846504    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728609000.088827    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "I0000 00:00:1728609000.088891    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-10-11 09:10:00.088903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "I0000 00:00:1728609000.088945    2049 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:65:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-10-11 09:10:00.101676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:65:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensors with tf.constant()\n",
        "scalar = tf.constant(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqWzyaORoZwW",
        "outputId": "99f6a775-dc46-4753-827b-e4e56aaa3cdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the number of dimensions of a tensor (ndim stands for number of dimensions)\n",
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTdOkRdAoje-",
        "outputId": "66ee8a31-51b7-4870-9536-8d4ed6fa4bbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector\n",
        "vector = tf.constant([10, 10])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUTnLUl3oqLT",
        "outputId": "75b8f5cf-d38c-4300-a76e-c543ec17ad0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the dimensions of our vector\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59LS4j_WoyMj",
        "outputId": "a2b5d5da-1da4-457d-a1ea-658c2624e49e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 7, 10]], dtype=int32)>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a matrix (has more than 1 dimension)\n",
        "matrix = tf.constant([[10, 7],\n",
        "                                  [7, 10]])\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIglofqApFRJ",
        "outputId": "ef0972b3-08a5-4a17-f35b-f07e999b73f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the dimensions of our matrix\n",
        "matrix.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ8Lq2V0pJ9b",
        "outputId": "bd7be4be-7eb7-4edb-98f3-7d05cd42f194"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-11 09:10:00.404065: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
              "array([[10.,  7.],\n",
              "       [ 8.,  2.],\n",
              "       [ 8.,  9.]], dtype=float16)>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create another matrix\n",
        "another_matrix = tf.constant([[10., 7.],\n",
        "                                                [8., 2.],\n",
        "                                                [8., 9.]],\n",
        "                                                dtype=tf.float16) # specify the data type with dtype parameter\n",
        "another_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R22f1zdptRt",
        "outputId": "f261800d-5bfa-4602-9944-5492ae11cf83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What's the dimensions of another_matrix?\n",
        "another_matrix.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqMu3VXTqATz",
        "outputId": "7928bd86-202e-4cd6-9060-4ca0111dc893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3],\n",
              "        [ 4,  5,  6]],\n",
              "\n",
              "       [[ 7,  8,  9],\n",
              "        [10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15],\n",
              "        [16, 17, 18]]], dtype=int32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's create a tensor\n",
        "tensor = tf.constant([[[1, 2, 3],\n",
        "                                   [4, 5, 6]],\n",
        "                                  [[7, 8, 9],\n",
        "                                   [10, 11, 12]],\n",
        "                                  [[13, 14, 15],\n",
        "                                   [16, 17, 18]]])\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4RqkgY3qc_Q",
        "outputId": "caa2ea79-e973-461e-df47-534ab4bcc211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensions of our tensor\n",
        "tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdRqeA8vrFzL"
      },
      "source": [
        "What we've created so far:\n",
        "\n",
        "* Scalar: a single number\n",
        "* Vector: a number with direction (e.g. wind speed and direction)\n",
        "* Matrix: a 2-dimensional array of numbers\n",
        "* Tensor: an n-dimensional array of numbers (when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr4WO3e0qPgD"
      },
      "source": [
        "### Creating tensors with tf.Variable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBXGOf6Bq09l",
        "outputId": "40221c26-1794-4bc1-f343-f34ea5b9b7c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create teh same tensor with tf.Variable()\n",
        "changeable_tensor = tf.Variable([10, 7])\n",
        "unchangeable_tensor = tf.constant([10, 7])\n",
        "\n",
        "changeable_tensor, unchangeable_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "17Z-id4CrBPK"
      },
      "outputs": [],
      "source": [
        "# Let's try change one of the elements in our changeable tensor\n",
        "\n",
        "# TypeError: 'ResourceVariable' object does not support item assignment\n",
        "# changeable_tensor[0] = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC2F1u81rS0u",
        "outputId": "d350471a-96ed-4ff4-987d-3c25729cb92c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How about we try .assign()\n",
        "changeable_tensor[0].assign(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bbot0SBEriAO"
      },
      "outputs": [],
      "source": [
        "# Let's try change our unchangeable tensor\n",
        "\n",
        "# TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n",
        "# unchangeable_tensor[0] = 7\n",
        "\n",
        "# AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n",
        "# unchangeable_tensor[0].assign(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOv6g-urMO5O"
      },
      "source": [
        "🔑 Note: Rarely in practice will you need to decide whether to use tf.constant or tf.Variable to create tensors, as TensorFlow does this for you. However, if in doubt, use tf.constant and change it later if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1siba2vYsFUi"
      },
      "source": [
        "### Creating random tensors\n",
        "\n",
        "Random tensors are tensors of some arbitrary size which contain random numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMwMAC45rsLa",
        "outputId": "61ef32d0-75f0-48e6-9cd0-d205c668f2bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[ True,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create 2 random (but the same) tensors\n",
        "random_1 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
        "random_1 = random_1.normal(shape=(3, 2))\n",
        "random_2 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
        "random_2 = random_2.normal(shape=(3, 2))\n",
        "\n",
        "# Are they equal?\n",
        "random_1, random_2, random_1 == random_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgxI_XOeYAuA"
      },
      "source": [
        "### Shuffle the order of elements in a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctsJQbAtNCNH",
        "outputId": "95e64af1-f8a5-438d-9282-1f244ebdf6b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4],\n",
              "       [ 2,  5]], dtype=int32)>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle a tensor (valuable for when you want to shuffle your data so the inherent order doesn't effect the learning)\n",
        "not_shuffled = tf.constant([[10, 7],\n",
        "                                            [3, 4],\n",
        "                                            [2, 5]])\n",
        "not_shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDgYcKiwY3Ni",
        "outputId": "dede7495-3d86-465d-e9cf-fbb55d6d95d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 3,  4],\n",
              "       [10,  7],\n",
              "       [ 2,  5]], dtype=int32)>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle our non-shuffled tensor (1st dimension)\n",
        "tf.random.shuffle(not_shuffled) # result should be different in each run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D-vrHsFZqkM",
        "outputId": "67473f05-f579-4d2d-c1cc-e21877da8252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4],\n",
              "       [ 2,  5]], dtype=int32)>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If the code depends on particular seeds to work, specify both global and operation-level seeds explicitly.\n",
        "tf.random.set_seed(42) # global level random seed\n",
        "tf.random.shuffle(not_shuffled, seed=42) # operation level random seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AXxCaCWnNPt"
      },
      "source": [
        "### Other ways to make tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZp5UEMPmuTV",
        "outputId": "bdb5097a-bb47-4508-b1f1-14d81d5afd32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "tf.ones([10, 7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3c3Bx5CnVJx",
        "outputId": "a6700a2e-2eed-49d4-eb9e-e2459d80ecb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "tf.zeros(shape=[3, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2hlV0xJnyo5"
      },
      "source": [
        "### Turn Numpy arrays into tensors\n",
        "\n",
        "The main difference between Numpy arrays and TensorFlow tensors is that tensors can be run on a GPU computing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9idzUD3DnhNs",
        "outputId": "c9ad8744-dea7-45ee-bc60-9eb8392264af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_A = np.arange(1, 25, dtype=np.int32) # create a Numpy array between 1 and 25\n",
        "np_A\n",
        "\n",
        "# X = tf.constant(some_matrix) # capital for matrix or tensor\n",
        "# y = tf.constant(vector) #non-capital for vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLAX_GXWoeyZ",
        "outputId": "f2ce5910-7d6c-47fe-fb2e-70af750b4b3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24], dtype=int32)>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_A = tf.constant(np_A)\n",
        "tf_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAG8cVX4uGiy",
        "outputId": "da7ac8d9-cf5b-4b29-d8d1-d1d1f7354c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15, 16],\n",
              "        [17, 18, 19, 20],\n",
              "        [21, 22, 23, 24]]], dtype=int32)>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_B = tf.constant(np_A, shape=(2, 3, 4))\n",
        "tf_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO5Yh4R2urbt",
        "outputId": "53488df7-d051-4c9e-d456-c648ff7598c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_B.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEBZssNulSs"
      },
      "source": [
        "## Getting information from tensors\n",
        "\n",
        "When dealing with tensors you probably want to be aware of the following attributes:\n",
        "* Shape\n",
        "* Rank\n",
        "* Axis or dimension\n",
        "* Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QZbKpP-Qudc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a rank 4 tensor (4 dimensions)\n",
        "rank_4_tensor = tf.zeros([2, 3, 4, 5])\n",
        "rank_4_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of rank_4_tensor: (2, 3, 4, 5)\n",
            "Datatype of every element in rank_4_tensor: <dtype: 'float32'>\n",
            "Dimentions (rank) of rank_4_tensor: 4\n",
            "Elements along the 0 axis of rank_4_tensor: 2\n",
            "Elements along the last axis of rank_4_tensor: 5\n",
            "Size (total number of element) of rank_4_tensor: 120\n"
          ]
        }
      ],
      "source": [
        "# Get various attributes of our tensor\n",
        "print(f'Shape of rank_4_tensor: {rank_4_tensor.shape}')\n",
        "print(f\"Datatype of every element in rank_4_tensor: {rank_4_tensor.dtype}\")\n",
        "print(f'Dimentions (rank) of rank_4_tensor: {rank_4_tensor.ndim}')\n",
        "print(f'Elements along the 0 axis of rank_4_tensor: {rank_4_tensor.shape[0]}')\n",
        "print(f'Elements along the last axis of rank_4_tensor: {rank_4_tensor.shape[-1]}')\n",
        "print(f'Size (total number of element) of rank_4_tensor: {tf.size(rank_4_tensor)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Indexing tensors\n",
        "\n",
        "Tensors can be indexed just like Python lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the first 2 elemnts of each dimension\n",
        "rank_4_tensor[:2, :2, :2, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the first element from each dimension from each index except for the final one\n",
        "rank_4_tensor[:1, :1, :1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([2, 2]), 2)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a rank 2 tensor (2 dimensions)\n",
        "rank_2_tensor = tf.constant([[10, 7], [3, 4]])\n",
        "rank_2_tensor.shape, rank_2_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4], dtype=int32)>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the last item of each of row of our rank 2 tensor\n",
        "rank_2_tensor[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[10],\n",
              "        [ 7]],\n",
              "\n",
              "       [[ 3],\n",
              "        [ 4]]], dtype=int32)>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add in extra dimension to our rank 2 tensor\n",
        "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
        "rank_3_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[10],\n",
              "        [ 7]],\n",
              "\n",
              "       [[ 3],\n",
              "        [ 4]]], dtype=int32)>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Alternative to add in extra dimension\n",
        "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" means expand the final axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
              "array([[[10,  7],\n",
              "        [ 3,  4]]], dtype=int32)>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Alternative to add in extra dimension\n",
        "tf.expand_dims(rank_2_tensor, axis=0) # expand the 0-axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manipulating tensors (tensor operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic operations\n",
        "\n",
        "`+`, `-`, `*`, `/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[20, 17],\n",
              "       [13, 14]], dtype=int32)>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can add values to a tensor using the addition operator\n",
        "tensor = tf.constant([[10, 7], [3, 4]])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[100,  70],\n",
              "       [ 30,  40]], dtype=int32)>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiplication\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 0, -3],\n",
              "       [-7, -6]], dtype=int32)>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Substraction\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[100,  70],\n",
              "       [ 30,  40]], dtype=int32)>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can use the tensorflow built-in function too\n",
        "# tf math function might be faster on GPU\n",
        "tf.multiply(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[20, 17],\n",
              "       [13, 14]], dtype=int32)>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.add(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
              "array([[1. , 0.7],\n",
              "       [0.3, 0.4]])>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.divide(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Original tensor is unchanged\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "In machine learning, matrix multiplication is one of the most common tensor operations.\n",
        "\n",
        "There are 2 rules our tensors (matrices) need to fulfill if we are going to matrix multiply them:\n",
        "1. The inner dimensions must match\n",
        "2. The resulting matrix has the shape of the outside dimensions\n",
        "\n",
        "Generally, when performing matrix multiplication on two tensors and one of the axes doesn't line up, you will tranpose (rather than reshape) one of the tensors to get satisify the matrix multiplication rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[121,  98],\n",
              "       [ 42,  37]], dtype=int32)>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication in TensorFlow (dot product)\n",
        "tf.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[100,  49],\n",
              "       [  9,  16]], dtype=int32)>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication with Python operator \"*\" (element-wise multiplication)\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[121,  98],\n",
              "       [ 42,  37]], dtype=int32)>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication with Python operator \"@\" (dot product)\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]], dtype=int32)>)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor (3, 2) tensor\n",
        "X = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Create another (3, 2) tensor\n",
        "Y = tf.constant([[7, 8], [9, 10], [11, 12]])\n",
        "\n",
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2) (2, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 61,  68,  75],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication of X and Y (note that the shape of X and Y is (3, 2), (3, 2) so we need to transpose one of them)\n",
        "# Changing the shape of Y to (2, 3)\n",
        "print(X.shape, tf.reshape(Y, shape=(2, 3)).shape)\n",
        "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 3) (3, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 58,  64],\n",
              "       [139, 154]], dtype=int32)>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try to change the shape of X instead of Y\n",
        "# note the result is different, the resulting matrix has the shape of the outer dimensions of the matrices being multiplied\n",
        "print(tf.reshape(X, shape=(2, 3)).shape, Y.shape)\n",
        "tf.reshape(X, shape=(2, 3)) @ Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reshape vs. Transpose\n",
        "\n",
        "**Reshape:** Changes the dimensions of a tensor.\n",
        "\n",
        "**Transpose:** Flips the axes of a tensor (swap dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 3, 5],\n",
              "        [2, 4, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 2, 3],\n",
              "        [4, 5, 6]], dtype=int32)>)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can do the same with transpose\n",
        "X, tf.transpose(X), tf.reshape(X, shape=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 3) (3, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [116, 128]], dtype=int32)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try matrix multiplication with transpose rather than reshape\n",
        "print(tf.transpose(X).shape, Y.shape)\n",
        "tf.matmul(tf.transpose(X), Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The dot product\n",
        "\n",
        "Matrix multiplication is also referred as the dot product.\n",
        "\n",
        "You can perform matrix multiplication using:\n",
        "\n",
        "* `tf.matmul()`\n",
        "* `tf.tensordot()`\n",
        "* `@`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]], dtype=int32)>)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2) (2, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 23,  29,  35],\n",
              "       [ 53,  67,  81],\n",
              "       [ 83, 105, 127]], dtype=int32)>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform matrix multiplication between X and Y (transpose Y)\n",
        "print(X.shape, tf.transpose(Y).shape)\n",
        "tf.tensordot(X, tf.transpose(Y), axes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2) (2, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 61,  68,  75],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform matrix multiplication between X and Y (reshaped Y)\n",
        "print(X.shape, tf.reshape(Y, shape=(2, 3)).shape)\n",
        "tf.tensordot(X, tf.reshape(Y, shape=(2, 3)), axes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Y:\n",
            "tf.Tensor(\n",
            "[[ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]], shape=(3, 2), dtype=int32) \n",
            "\n",
            "Y reshaped to (2, 3):\n",
            "tf.Tensor(\n",
            "[[ 7  8  9]\n",
            " [10 11 12]], shape=(2, 3), dtype=int32) \n",
            "\n",
            "Y transposed:\n",
            "tf.Tensor(\n",
            "[[ 7  9 11]\n",
            " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Check the values of Y, reshape Y and transposed Y\n",
        "print(\"Normal Y:\")\n",
        "print(Y, \"\\n\") # \"\\n\" is for newline\n",
        "\n",
        "print(\"Y reshaped to (2, 3):\")\n",
        "print(tf.reshape(Y, (2, 3)), \"\\n\")\n",
        "\n",
        "print(\"Y transposed:\")\n",
        "print(tf.transpose(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Changing datatype of a tensor\n",
        "\n",
        "Sometimes you'll want to alter the default datatype of your tensor.\n",
        "\n",
        "This is common when you want to compute using less precision (e.g. 16-bit floating point numbers vs. 32-bit floating point numbers).\n",
        "\n",
        "Computing with less precision is useful on devices with less computing capacity such as mobile devices (because the less bits, the less space the computations require).\n",
        "\n",
        "You can change the datatype of a tensor using `tf.cast()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7], dtype=int32)>)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a new tensor with default datatype (float32)\n",
        "B = tf.constant([1.7, 7.4])\n",
        "\n",
        "# Create a new tensor with default datatype (int32)\n",
        "C = tf.constant([1, 7])\n",
        "B, C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change from float32 to float16 (reduced precision)\n",
        "B = tf.cast(B, dtype=tf.float16)\n",
        "B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change from int32 to float32\n",
        "E = tf.cast(C, dtype=tf.float32)\n",
        "E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1., 7.], dtype=float16)>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "E_float16 = tf.cast(E, dtype=tf.float16)\n",
        "E_float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor aggregation\n",
        "\n",
        "Aggregating tensors = condensing them from multiple values down to a smaller amount of values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10], dtype=int32)>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "D = tf.constant([-7, -10])\n",
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the absolute values\n",
        "tf.abs(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's go through the following forms of aggregation:\n",
        "\n",
        "* Get the minimum\n",
        "* Get the maximum\n",
        "* Get the mean of a tensor\n",
        "* Get the sum of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([59, 14, 27, 60, 49, 43, 13, 23, 53, 62, 24, 18, 74, 79, 47, 95, 95,\n",
              "       49, 44, 81, 15, 39, 52, 16, 62, 65,  1, 27, 56, 49, 50, 76,  7, 63,\n",
              "       30, 27, 32, 26, 44, 36, 29, 51, 25, 64, 13, 72, 31, 19, 49, 11])>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with values between 0 and 100 of size 50\n",
        "E = tf.constant(np.random.randint(0, 100, size=50))\n",
        "E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int32, numpy=50>, TensorShape([50]), 1)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.size(E), E.shape, E.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the minimum\n",
        "tf.reduce_min(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=95>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the maximum\n",
        "tf.reduce_max(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the mean\n",
        "tf.reduce_mean(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=2146>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sum\n",
        "tf.reduce_sum(E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise:** With what we have just learnd, find the variance and standard deviation of our `E` tensor using TensorFlow methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=530.6336>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the variance\n",
        "float32_E = tf.cast(E, dtype=tf.float32)\n",
        "tf.math.reduce_variance(float32_E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=23.035486>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the standard deviation\n",
        "tf.math.reduce_std(float32_E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the positional minimum and maximum of a tensor (argmin and argmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "F = tf.random.uniform(shape=[50])\n",
        "F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index of the minimum value: 16\n",
            "Minimum value: 0.009463667869567871\n"
          ]
        }
      ],
      "source": [
        "# Find the minimum value's index and the minimum value\n",
        "print(f\"Index of the minimum value: {tf.argmin(F).numpy()}\")\n",
        "print(f\"Minimum value: {tf.reduce_min(F).numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The maximum value of F is at position: 42\n",
            "The maximum value of F is: 0.967138409614563\n"
          ]
        }
      ],
      "source": [
        "# Find the largest value's index and the largest value\n",
        "print(f'The maximum value of F is at position: {tf.argmax(F)}')\n",
        "print(f'The maximum value of F is: {tf.reduce_max(F)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Squeezing a tensor (removing all 1-dimension axes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
              "array([[[[[0.68789124, 0.48447883, 0.9309944 , 0.252187  , 0.73115396,\n",
              "           0.89256823, 0.94674826, 0.7493341 , 0.34925628, 0.54718256,\n",
              "           0.26160395, 0.69734323, 0.11962581, 0.53484344, 0.7148968 ,\n",
              "           0.87501776, 0.33967495, 0.17377627, 0.4418521 , 0.9008261 ,\n",
              "           0.13803864, 0.12217975, 0.5754491 , 0.9417181 , 0.9186585 ,\n",
              "           0.59708476, 0.6109482 , 0.82086265, 0.83269787, 0.8915849 ,\n",
              "           0.01377225, 0.49807465, 0.57503664, 0.6856195 , 0.75972784,\n",
              "           0.908944  , 0.40900218, 0.8765154 , 0.53890026, 0.42733097,\n",
              "           0.401173  , 0.66623247, 0.16348064, 0.18220246, 0.97040176,\n",
              "           0.06139731, 0.53034747, 0.9869994 , 0.4746945 , 0.8646754 ]]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G = tf.constant(tf.random.uniform(shape=[50]), shape=(1, 1, 1, 1, 50))\n",
        "G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([0.68789124, 0.48447883, 0.9309944 , 0.252187  , 0.73115396,\n",
              "       0.89256823, 0.94674826, 0.7493341 , 0.34925628, 0.54718256,\n",
              "       0.26160395, 0.69734323, 0.11962581, 0.53484344, 0.7148968 ,\n",
              "       0.87501776, 0.33967495, 0.17377627, 0.4418521 , 0.9008261 ,\n",
              "       0.13803864, 0.12217975, 0.5754491 , 0.9417181 , 0.9186585 ,\n",
              "       0.59708476, 0.6109482 , 0.82086265, 0.83269787, 0.8915849 ,\n",
              "       0.01377225, 0.49807465, 0.57503664, 0.6856195 , 0.75972784,\n",
              "       0.908944  , 0.40900218, 0.8765154 , 0.53890026, 0.42733097,\n",
              "       0.401173  , 0.66623247, 0.16348064, 0.18220246, 0.97040176,\n",
              "       0.06139731, 0.53034747, 0.9869994 , 0.4746945 , 0.8646754 ],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G_squeezed = tf.squeeze(G)\n",
        "G_squeezed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One-hot encoding\n",
        "\n",
        "One-hot encoding converts categorical data into a binary matrix where each category is represented by a unique column with a value of 1 for the presence of the category and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of indices\n",
        "some_list = [0, 1, 2, 3] # could be red, green, blue, purple\n",
        "\n",
        "# One hot encode our list of indices\n",
        "tf.one_hot(some_list, depth=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
              "array([[b'on', b'off', b'off', b'off'],\n",
              "       [b'off', b'on', b'off', b'off'],\n",
              "       [b'off', b'off', b'on', b'off'],\n",
              "       [b'off', b'off', b'off', b'on']], dtype=object)>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Specify custom values for one hot encoding\n",
        "tf.one_hot(some_list, depth=len(some_list), on_value=\"on\", off_value=\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Squaring, log, square root\n",
        "\n",
        "\n",
        "* `tf.square()` - get the square of every value in a tensor.\n",
        "* `tf.sqrt()` - get the squareroot of every value in a tensor (note: the elements need to be floats or this will error).\n",
        "* `tf.math.log()` - get the natural log of every value in a tensor (elements need to floats).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H = tf.range(1, 10)\n",
        "H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81], dtype=int32)>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Square\n",
        "tf.square(H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([1.       , 1.4142135, 1.7320508, 2.       , 2.2360678, 2.4494896,\n",
              "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Square root\n",
        "tf.sqrt(tf.cast(H, dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
              "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logarithm\n",
        "tf.math.log(tf.cast(H, dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipulating tf.Variable tensors\n",
        "\n",
        "Tensors created with tf.Variable() can be changed in place using methods such as:\n",
        "\n",
        "* `.assign()` - assign a different value to a particular index of a variable tensor.\n",
        "* `.add_assign()` - add to an existing value and reassign it at a particular index of a variable tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([0, 1, 2, 3, 4])>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a variable tensor\n",
        "I = tf.Variable(np.arange(0, 5))\n",
        "I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int64, numpy=array([ 0,  1,  2,  3, 50])>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assign the final value a new value of 50\n",
        "I.assign([0, 1, 2, 3, 50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([ 0,  1,  2,  3, 50])>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The change happens in place (the last value is now 50, not 4)\n",
        "I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([10, 11, 12, 13, 60])>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add 10 to every element in I\n",
        "I.assign_add([10, 10, 10, 10, 10])\n",
        "# Again, the change happens in place\n",
        "I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensors and NumPy\n",
        "\n",
        "We've seen some examples of tensors interact with NumPy arrays, such as, using NumPy arrays to create tensors.\n",
        "\n",
        "Tensors can also be converted to NumPy arrays using:\n",
        "\n",
        "* np.array() - pass a tensor to convert to an ndarray (NumPy's main datatype).\n",
        "* tensor.numpy() - call on a tensor to convert to an ndarray.\n",
        "\n",
        "Doing this is helpful as it makes tensors iterable as well as allows us to use any of NumPy's methods on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>,\n",
              " tensorflow.python.framework.ops.EagerTensor)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor directly from a Numpy array\n",
        "J = tf.constant(np.array([3., 7., 10.]))\n",
        "J, type(J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert out tensor back to a Numpy array\n",
        "np_J = J.numpy()\n",
        "np_J, type(np_J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2nd way to convert tensor to Numpy array\n",
        "np_J_2 = np.array(J)\n",
        "np_J_2, type(np_J_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tf.float64, tf.float32)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The default data types of each are slightly different\n",
        "np_J = tf.constant(np.array([3., 7., 10.]))\n",
        "ts_J = tf.constant([3., 7., 10.])\n",
        "\n",
        "np_J.dtype, ts_J.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding access to GPUs\n",
        "\n",
        "You can check if you've got access to a GPU using tf.config.list_physical_devices()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Oct 11 09:10:06 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4070 ...    On  |   00000000:65:00.0 Off |                  N/A |\n",
            "| N/A   54C    P3             12W /   70W |    6303MiB /   8188MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2049      C   /python3.12                                 N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🛠 TensorFlow Fundamentals Exercises\n",
        "\n",
        "1. Create a vector, scalar, matrix and tensor with values of your choosing using tf.constant().\n",
        "2. Find the shape, rank and size of the tensors you created in 1.\n",
        "3. Create two tensors containing random values between 0 and 1 with shape [5, 300].\n",
        "4. Multiply the two tensors you created in 3 using matrix multiplication.\n",
        "5. Multiply the two tensors you created in 3 using dot product.\n",
        "6. Create a tensor with random values between 0 and 1 with shape [224, 224, 3].\n",
        "7. Find the min and max values of the tensor you created in 6 along the first axis.\n",
        "8. Create a tensor with random values of shape [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
        "9. Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.\n",
        "10. One-hot encode the tensor you created in 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=7>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 2, 3],\n",
              "        [4, 5, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
              " array([[[ 1,  2,  3],\n",
              "         [ 4,  5,  6]],\n",
              " \n",
              "        [[ 7,  8,  9],\n",
              "         [10, 11, 12]],\n",
              " \n",
              "        [[13, 14, 15],\n",
              "         [16, 17, 18]]], dtype=int32)>)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Create a vector, scalar, matrix and tensor with values of your choosing using tf.constant().\n",
        "vector = tf.constant([1, 2, 3])\n",
        "scalar = tf.constant(7)\n",
        "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "tensor = tf.constant([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]], [[13, 14, 15], [16, 17, 18]]])\n",
        "\n",
        "vector, scalar, matrix, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([3, 2, 3]), 3, <tf.Tensor: shape=(), dtype=int32, numpy=18>)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. Find the shape, rank and size of the tensors you created in 1.\n",
        "tensor.shape, tensor.ndim, tf.size(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5, 300), dtype=float32, numpy=\n",
              " array([[0.6645621 , 0.44100678, 0.3528825 , ..., 0.31410468, 0.7593535 ,\n",
              "         0.03699052],\n",
              "        [0.532024  , 0.29129946, 0.10571766, ..., 0.54052293, 0.31425726,\n",
              "         0.2200619 ],\n",
              "        [0.08404207, 0.03614604, 0.97732127, ..., 0.21516645, 0.9786098 ,\n",
              "         0.00726748],\n",
              "        [0.7396945 , 0.6653172 , 0.0787828 , ..., 0.7117733 , 0.07013571,\n",
              "         0.9409125 ],\n",
              "        [0.15861344, 0.12024033, 0.27218235, ..., 0.8824879 , 0.1432488 ,\n",
              "         0.44135118]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 300), dtype=float32, numpy=\n",
              " array([[0.68789124, 0.48447883, 0.9309944 , ..., 0.6920762 , 0.33180213,\n",
              "         0.9212563 ],\n",
              "        [0.27369928, 0.10631859, 0.6218617 , ..., 0.4382149 , 0.30427706,\n",
              "         0.51477313],\n",
              "        [0.00920248, 0.37280262, 0.8177401 , ..., 0.56786287, 0.49201214,\n",
              "         0.9892651 ],\n",
              "        [0.88608265, 0.08672249, 0.12160683, ..., 0.91770685, 0.72545695,\n",
              "         0.8280058 ],\n",
              "        [0.36690474, 0.9200133 , 0.9646884 , ..., 0.69012   , 0.7137332 ,\n",
              "         0.2584542 ]], dtype=float32)>)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3. Create two tensors containing random values between 0 and 1 with shape [5, 300].\n",
        "tf.random.set_seed(42)\n",
        "tensor_1 = tf.random.uniform(shape=[5, 300])\n",
        "tensor_2 = tf.random.uniform(shape=[5, 300])\n",
        "\n",
        "tensor_1, tensor_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[76.27554 , 79.17827 , 77.82468 , 79.390816, 79.37842 ],\n",
              "       [72.70598 , 73.674446, 73.71501 , 74.18447 , 73.72763 ],\n",
              "       [75.73994 , 76.49056 , 74.43401 , 78.80334 , 77.701225],\n",
              "       [68.98679 , 75.53526 , 74.58016 , 76.19388 , 75.24947 ],\n",
              "       [75.563354, 81.79909 , 78.68235 , 80.158264, 80.48132 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Multiply the two tensors you created in 3 using matrix multiplication.\n",
        "tf.matmul(tensor_1, tf.reshape(tensor_2, shape=(300, 5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[80.33309 , 73.40606 , 77.15882 , 73.98497 , 80.90113 ],\n",
              "       [75.14486 , 68.80302 , 74.241905, 71.84128 , 75.60254 ],\n",
              "       [79.75885 , 75.64509 , 77.79609 , 74.74909 , 80.56139 ],\n",
              "       [75.084404, 69.06293 , 74.30793 , 72.27636 , 76.05752 ],\n",
              "       [85.05516 , 74.266624, 78.00625 , 74.8864  , 83.135666]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5. Multiply the two tensors you created in 3 using dot product.\n",
        "tf.tensordot(tensor_1, tf.transpose(tensor_2), axes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[0.7413678 , 0.62854624, 0.01738465],\n",
              "        [0.3431449 , 0.51063764, 0.3777541 ],\n",
              "        [0.07321596, 0.02137029, 0.2871771 ],\n",
              "        ...,\n",
              "        [0.98953485, 0.45382905, 0.2006687 ],\n",
              "        [0.6295223 , 0.4937899 , 0.01816809],\n",
              "        [0.95386636, 0.11542463, 0.85691285]],\n",
              "\n",
              "       [[0.78435016, 0.7826872 , 0.87936425],\n",
              "        [0.24906898, 0.3207239 , 0.10955775],\n",
              "        [0.543224  , 0.7151396 , 0.40334642],\n",
              "        ...,\n",
              "        [0.2445668 , 0.01746976, 0.9036933 ],\n",
              "        [0.02975535, 0.592268  , 0.9877522 ],\n",
              "        [0.36701274, 0.33112562, 0.5638567 ]],\n",
              "\n",
              "       [[0.15829337, 0.7288823 , 0.3366307 ],\n",
              "        [0.70792687, 0.16910625, 0.9429966 ],\n",
              "        [0.10120225, 0.5919596 , 0.8687303 ],\n",
              "        ...,\n",
              "        [0.28134012, 0.10011208, 0.37038183],\n",
              "        [0.77874243, 0.05421627, 0.4664607 ],\n",
              "        [0.2549187 , 0.7968637 , 0.83405185]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.32922816, 0.06343532, 0.23936498],\n",
              "        [0.42692196, 0.3615111 , 0.901929  ],\n",
              "        [0.8320831 , 0.21068895, 0.08272386],\n",
              "        ...,\n",
              "        [0.65110314, 0.40780962, 0.25967455],\n",
              "        [0.9018173 , 0.8245677 , 0.16757596],\n",
              "        [0.41854453, 0.19092035, 0.2523303 ]],\n",
              "\n",
              "       [[0.7064005 , 0.222404  , 0.82219553],\n",
              "        [0.8235872 , 0.76544905, 0.80999327],\n",
              "        [0.1100682 , 0.00520217, 0.6127168 ],\n",
              "        ...,\n",
              "        [0.98068535, 0.8958733 , 0.17706168],\n",
              "        [0.4252876 , 0.02087164, 0.496238  ],\n",
              "        [0.6599953 , 0.58505726, 0.7089884 ]],\n",
              "\n",
              "       [[0.90045786, 0.45803344, 0.9050728 ],\n",
              "        [0.92233   , 0.38456154, 0.30329156],\n",
              "        [0.03238845, 0.18773472, 0.9096625 ],\n",
              "        ...,\n",
              "        [0.4445815 , 0.04578841, 0.21090853],\n",
              "        [0.25966525, 0.24412918, 0.76123405],\n",
              "        [0.9643831 , 0.32687283, 0.4828869 ]]], dtype=float32)>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. Create a tensor with random values between 0 and 1 with shape [224, 224, 3].\n",
        "tensor_3 = tf.random.uniform(shape=[224, 224, 3])\n",
        "tensor_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 3), dtype=float32, numpy=\n",
              "array([[2.67446041e-03, 2.14838982e-03, 1.05965137e-03],\n",
              "       [5.47564030e-03, 2.21121311e-03, 4.15408611e-03],\n",
              "       [3.72385979e-03, 5.20217419e-03, 9.02771950e-04],\n",
              "       [1.11603737e-03, 6.35766983e-03, 3.18384171e-03],\n",
              "       [2.10273266e-03, 5.84840775e-04, 1.05011463e-03],\n",
              "       [4.26018238e-03, 1.58730745e-02, 1.21641159e-03],\n",
              "       [6.51884079e-03, 1.17063522e-03, 2.71463394e-03],\n",
              "       [5.67364693e-03, 8.54074955e-03, 1.52909756e-02],\n",
              "       [7.19797611e-03, 8.43882561e-04, 1.91795826e-03],\n",
              "       [4.71234322e-04, 6.39832020e-03, 2.17664242e-03],\n",
              "       [2.41947174e-03, 5.75447083e-03, 1.54391527e-02],\n",
              "       [9.96232033e-04, 1.06847286e-03, 1.08550787e-02],\n",
              "       [7.00187683e-03, 3.46624851e-03, 2.44665146e-03],\n",
              "       [1.11377239e-03, 7.05718994e-05, 2.76803970e-03],\n",
              "       [3.22699547e-03, 9.34267044e-03, 4.85146046e-03],\n",
              "       [2.55906582e-03, 3.21245193e-03, 2.09597349e-02],\n",
              "       [4.42552567e-03, 6.46495819e-03, 1.56283379e-03],\n",
              "       [1.74760818e-04, 8.91327858e-04, 7.24554062e-03],\n",
              "       [6.97255135e-04, 5.13529778e-03, 2.70259380e-03],\n",
              "       [6.96301460e-04, 1.15126371e-02, 1.75446272e-02],\n",
              "       [1.21183395e-02, 1.34944916e-03, 3.73733044e-03],\n",
              "       [2.35307217e-03, 1.35254860e-03, 3.71372700e-03],\n",
              "       [1.06908083e-02, 1.62684917e-03, 5.34749031e-03],\n",
              "       [2.34341621e-03, 3.37314606e-03, 1.15585327e-03],\n",
              "       [2.34997272e-03, 6.55043125e-03, 1.56080723e-03],\n",
              "       [1.43407583e-02, 5.88893890e-05, 3.34930420e-03],\n",
              "       [6.97970390e-03, 8.14437866e-04, 3.18539143e-03],\n",
              "       [2.90274620e-03, 5.66852093e-03, 2.88796425e-03],\n",
              "       [5.81216812e-03, 2.59160995e-04, 2.24125385e-03],\n",
              "       [2.09927559e-03, 2.30789185e-04, 1.93405151e-03],\n",
              "       [9.49025154e-04, 1.23238564e-03, 2.39002705e-03],\n",
              "       [7.75778294e-03, 1.85263157e-03, 4.09388542e-03],\n",
              "       [4.92572784e-04, 9.56296921e-04, 3.77678871e-03],\n",
              "       [1.65581703e-03, 1.10888481e-03, 8.71896744e-04],\n",
              "       [3.63492966e-03, 2.70855427e-03, 4.44495678e-03],\n",
              "       [1.47342682e-04, 5.44428825e-04, 8.76605511e-03],\n",
              "       [7.17759132e-03, 9.60123539e-03, 1.71692371e-02],\n",
              "       [5.79750538e-03, 4.69088554e-04, 1.26063824e-03],\n",
              "       [2.20596790e-03, 6.04259968e-03, 5.84363937e-04],\n",
              "       [1.55568123e-03, 3.22818756e-03, 9.23848152e-03],\n",
              "       [8.91160965e-03, 5.44500351e-03, 1.29337311e-02],\n",
              "       [4.36019897e-03, 2.96604633e-03, 5.83374500e-03],\n",
              "       [8.36467743e-03, 2.80857086e-04, 5.78927994e-03],\n",
              "       [6.96837902e-03, 2.01308727e-03, 1.36235952e-02],\n",
              "       [5.77437878e-03, 8.38220119e-03, 1.27208233e-03],\n",
              "       [1.09267235e-03, 6.71052933e-03, 3.95452976e-03],\n",
              "       [7.77006149e-04, 3.15213203e-03, 4.13119793e-03],\n",
              "       [6.47675991e-03, 8.89062881e-04, 1.24269724e-02],\n",
              "       [4.44650650e-03, 4.18877602e-03, 2.31397152e-03],\n",
              "       [6.82342052e-03, 1.01327896e-03, 1.64389610e-03],\n",
              "       [1.06036663e-03, 6.64472580e-04, 1.57248974e-03],\n",
              "       [2.57611275e-04, 4.67598438e-03, 1.30665302e-03],\n",
              "       [8.89301300e-04, 6.95943832e-03, 2.74193287e-03],\n",
              "       [7.72356987e-04, 6.64949417e-04, 2.14612484e-03],\n",
              "       [8.36491585e-04, 1.91324949e-02, 1.49726868e-03],\n",
              "       [3.03912163e-03, 2.97713280e-03, 1.32095814e-02],\n",
              "       [2.23839283e-03, 1.10685825e-03, 6.43730164e-04],\n",
              "       [6.89935684e-03, 1.38878822e-03, 6.58547878e-03],\n",
              "       [2.86698341e-03, 3.27777863e-03, 2.22957134e-03],\n",
              "       [3.66258621e-03, 4.66775894e-03, 3.15856934e-03],\n",
              "       [4.59432602e-03, 1.89495087e-03, 3.32355499e-03],\n",
              "       [4.84859943e-03, 4.58478928e-04, 5.15949726e-03],\n",
              "       [6.46424294e-03, 4.74750996e-03, 6.48760796e-03],\n",
              "       [9.57190990e-03, 2.26974487e-03, 5.25486469e-03],\n",
              "       [2.71642208e-03, 3.38733196e-03, 2.75254250e-03],\n",
              "       [3.19898129e-03, 1.74939632e-03, 8.20040703e-04],\n",
              "       [2.67708302e-03, 1.39939785e-03, 4.85157967e-03],\n",
              "       [3.98027897e-03, 1.34527683e-03, 3.30317020e-03],\n",
              "       [7.91192055e-03, 7.65275955e-03, 9.01818275e-03],\n",
              "       [2.79998779e-03, 3.09896469e-03, 1.40535831e-03],\n",
              "       [3.52119207e-02, 4.05311584e-06, 5.11169434e-03],\n",
              "       [4.50015068e-03, 1.81233883e-03, 6.10733032e-03],\n",
              "       [1.24347210e-03, 1.10936165e-03, 3.00788879e-03],\n",
              "       [3.85963917e-03, 3.21877003e-03, 2.25245953e-03],\n",
              "       [2.97937393e-02, 1.84963942e-02, 4.73785400e-03],\n",
              "       [1.14896297e-02, 2.09009647e-03, 2.11572647e-03],\n",
              "       [2.27999687e-03, 1.88016891e-03, 2.78091431e-03],\n",
              "       [6.11388683e-03, 5.91874123e-04, 1.23977661e-04],\n",
              "       [3.33428383e-04, 7.77959824e-04, 4.23836708e-03],\n",
              "       [9.95922089e-03, 1.98233128e-03, 2.68340111e-04],\n",
              "       [1.39617920e-03, 1.35613680e-02, 8.93509388e-03],\n",
              "       [3.40461731e-03, 2.01821327e-04, 7.45534897e-03],\n",
              "       [6.60490990e-03, 5.24938107e-03, 2.03943253e-03],\n",
              "       [5.26690483e-03, 1.57070160e-03, 8.08572769e-03],\n",
              "       [3.40461731e-04, 4.34172153e-03, 7.90810585e-03],\n",
              "       [2.23064423e-03, 1.88791752e-03, 5.23710251e-03],\n",
              "       [1.85906887e-03, 9.91106033e-03, 3.78286839e-03],\n",
              "       [8.42690468e-03, 1.06985569e-02, 2.67732143e-03],\n",
              "       [1.13210678e-02, 2.26855278e-04, 6.19280338e-03],\n",
              "       [1.99794769e-03, 8.67319107e-03, 1.36413574e-02],\n",
              "       [1.25052929e-02, 1.13725662e-04, 1.26099586e-03],\n",
              "       [6.31105900e-03, 2.91252136e-03, 1.65724754e-03],\n",
              "       [9.09161568e-03, 2.24590302e-03, 3.55303288e-03],\n",
              "       [2.05278397e-03, 5.26309013e-04, 2.34293938e-03],\n",
              "       [1.51240826e-03, 2.27189064e-03, 3.74162197e-03],\n",
              "       [6.31892681e-03, 3.12268734e-03, 2.85530090e-03],\n",
              "       [8.32402706e-03, 3.08668613e-03, 2.14576721e-05],\n",
              "       [2.61294842e-03, 2.36034393e-05, 1.31090879e-02],\n",
              "       [3.03649902e-03, 5.84244728e-04, 4.89830971e-04],\n",
              "       [9.70363617e-04, 1.29282475e-03, 5.99622726e-05],\n",
              "       [2.40743160e-03, 6.87015057e-03, 1.37351751e-02],\n",
              "       [3.59189510e-03, 5.67305088e-03, 2.03621387e-03],\n",
              "       [5.02717495e-03, 4.54878807e-03, 1.80172920e-03],\n",
              "       [1.04178190e-02, 5.63859940e-04, 2.55405903e-03],\n",
              "       [7.10594654e-03, 1.69265270e-03, 1.17418766e-02],\n",
              "       [1.06832981e-02, 1.20782852e-03, 1.00317001e-02],\n",
              "       [2.95400620e-04, 2.42483616e-03, 1.76954269e-03],\n",
              "       [2.81536579e-03, 3.68356705e-04, 5.10013103e-03],\n",
              "       [3.79216671e-03, 1.72877312e-03, 4.79519367e-03],\n",
              "       [7.00831413e-04, 4.33909893e-03, 1.63090229e-02],\n",
              "       [9.45806503e-04, 6.33239746e-03, 2.74944305e-03],\n",
              "       [4.89389896e-03, 4.48477268e-03, 1.47454739e-02],\n",
              "       [8.99100304e-03, 2.46000290e-03, 3.84163857e-03],\n",
              "       [2.79855728e-03, 2.73203850e-03, 3.49652767e-03],\n",
              "       [1.35266781e-03, 3.06129456e-04, 2.66301632e-03],\n",
              "       [2.69782543e-03, 2.23660469e-03, 2.56097317e-03],\n",
              "       [1.26576424e-03, 2.43461132e-03, 3.74078751e-04],\n",
              "       [5.79655170e-03, 1.38449669e-03, 4.63724136e-04],\n",
              "       [1.08083487e-02, 5.27501106e-04, 6.14428520e-03],\n",
              "       [1.17242336e-03, 9.29474831e-04, 3.69632244e-03],\n",
              "       [7.64966011e-04, 9.47093964e-03, 5.87892532e-03],\n",
              "       [9.55760479e-03, 3.22461128e-04, 8.41963291e-03],\n",
              "       [1.42312050e-03, 2.19857693e-03, 6.93082809e-04],\n",
              "       [4.76241112e-04, 4.60505486e-04, 4.45055962e-03],\n",
              "       [5.20133972e-03, 7.31039047e-03, 1.31424665e-02],\n",
              "       [6.30974770e-04, 6.08813763e-03, 8.40902328e-04],\n",
              "       [1.68502331e-03, 3.65996361e-03, 7.21693039e-04],\n",
              "       [3.14176083e-03, 1.35171413e-03, 1.72604322e-02],\n",
              "       [1.13952160e-03, 1.08766556e-03, 2.08854675e-03],\n",
              "       [8.16583633e-03, 2.05707550e-03, 5.65218925e-03],\n",
              "       [5.12433052e-03, 2.74574757e-03, 6.39081001e-03],\n",
              "       [1.20600462e-02, 7.45868683e-03, 2.94506550e-03],\n",
              "       [1.24073029e-03, 3.75509262e-04, 1.32579803e-02],\n",
              "       [4.90331650e-03, 2.39908695e-03, 6.16645813e-03],\n",
              "       [1.15740299e-03, 5.91003895e-03, 1.57802105e-02],\n",
              "       [8.35359097e-03, 2.30193138e-04, 1.42168999e-03],\n",
              "       [5.94854355e-03, 3.70121002e-03, 8.93259048e-03],\n",
              "       [5.03897667e-04, 5.86748123e-04, 2.77614594e-03],\n",
              "       [7.31503963e-03, 2.86948681e-03, 1.23095512e-03],\n",
              "       [1.30534172e-04, 5.16617298e-03, 2.14412212e-02],\n",
              "       [4.39572334e-03, 3.85272503e-03, 1.10950470e-02],\n",
              "       [1.63710117e-03, 2.40910053e-03, 1.62100792e-03],\n",
              "       [2.30922699e-02, 1.39594078e-04, 6.65736198e-03],\n",
              "       [6.79004192e-03, 1.43945217e-03, 5.50186634e-03],\n",
              "       [4.55975533e-04, 4.69779968e-03, 2.97427177e-03],\n",
              "       [1.10237598e-02, 1.78362131e-02, 3.09622288e-03],\n",
              "       [3.40390205e-03, 4.50634956e-03, 3.20327282e-03],\n",
              "       [6.91151619e-03, 3.67760658e-04, 6.56068325e-03],\n",
              "       [3.64780426e-04, 8.57520103e-03, 2.74419785e-04],\n",
              "       [4.48822975e-04, 2.01964378e-03, 2.20048428e-03],\n",
              "       [9.23991203e-04, 1.03474855e-02, 1.37901306e-03],\n",
              "       [1.40655041e-03, 4.85885143e-03, 1.33919716e-03],\n",
              "       [4.02259827e-03, 1.39447451e-02, 4.33206558e-04],\n",
              "       [1.30522251e-02, 5.27381897e-04, 8.05854797e-05],\n",
              "       [6.44350052e-03, 1.13844872e-03, 5.55717945e-03],\n",
              "       [1.65212154e-03, 7.64882565e-03, 3.62396240e-03],\n",
              "       [4.00543213e-04, 5.25736809e-03, 1.47690773e-02],\n",
              "       [4.04691696e-03, 5.15913963e-03, 5.04493713e-04],\n",
              "       [1.40118599e-03, 1.51968002e-03, 1.93536282e-03],\n",
              "       [1.19214058e-02, 1.70171261e-03, 5.42283058e-04],\n",
              "       [1.35878325e-02, 5.10203838e-03, 7.83395767e-03],\n",
              "       [6.55746460e-03, 2.58982182e-03, 5.68473339e-03],\n",
              "       [5.87081909e-03, 5.36441803e-05, 9.66787338e-05],\n",
              "       [8.72159004e-03, 1.04211569e-02, 3.45945358e-04],\n",
              "       [5.51605225e-03, 3.05867195e-03, 5.38325310e-03],\n",
              "       [8.21113586e-03, 8.70347023e-04, 9.08732414e-04],\n",
              "       [8.14318657e-04, 1.25992298e-03, 3.35204601e-03],\n",
              "       [7.26342201e-04, 6.23154640e-03, 3.81159782e-03],\n",
              "       [1.69491768e-03, 2.02107430e-03, 3.56483459e-03],\n",
              "       [4.79602814e-03, 5.17249107e-04, 1.80149078e-03],\n",
              "       [3.14712524e-05, 6.72399998e-03, 5.53131104e-04],\n",
              "       [6.50525093e-04, 4.27484512e-04, 7.99536705e-04],\n",
              "       [6.46424294e-03, 1.86300278e-03, 7.88450241e-03],\n",
              "       [4.45580482e-03, 9.25421715e-04, 1.81329250e-03],\n",
              "       [4.23824787e-03, 3.61382961e-03, 9.60302353e-03],\n",
              "       [1.34366751e-02, 3.77631187e-03, 1.44839287e-02],\n",
              "       [2.87878513e-03, 1.56164169e-04, 1.89675093e-02],\n",
              "       [9.02795792e-03, 1.94311142e-04, 5.09762764e-03],\n",
              "       [4.16636467e-04, 1.28637552e-02, 5.84089756e-03],\n",
              "       [1.09429359e-02, 3.41391563e-03, 4.74452972e-04],\n",
              "       [9.36579704e-03, 1.56283379e-04, 9.13131237e-03],\n",
              "       [1.88720226e-03, 4.54902649e-03, 8.44597816e-04],\n",
              "       [3.35454941e-04, 1.52325630e-03, 7.26473331e-03],\n",
              "       [1.46639347e-03, 3.92222404e-03, 1.02258921e-02],\n",
              "       [8.66031647e-03, 2.41978168e-02, 7.86638260e-03],\n",
              "       [5.57124615e-03, 5.27358055e-03, 2.77888775e-03],\n",
              "       [5.57100773e-03, 3.35228443e-03, 8.60810280e-04],\n",
              "       [2.11000443e-04, 5.33294678e-03, 3.86190414e-03],\n",
              "       [6.46257401e-03, 5.24640083e-04, 4.19938564e-03],\n",
              "       [9.41038132e-03, 1.18491650e-02, 5.96606731e-03],\n",
              "       [5.91123104e-03, 6.49094582e-04, 4.23610210e-03],\n",
              "       [4.94515896e-03, 3.58390808e-03, 1.24957561e-02],\n",
              "       [1.07383728e-03, 1.94668770e-03, 6.86645508e-04],\n",
              "       [1.68502331e-03, 9.44375992e-04, 6.39152527e-03],\n",
              "       [2.69067287e-03, 5.28097153e-05, 3.37982178e-03],\n",
              "       [1.62087679e-02, 1.55184269e-02, 3.26633453e-03],\n",
              "       [4.81665134e-03, 1.42173767e-02, 4.78518009e-03],\n",
              "       [1.17695332e-03, 1.34038925e-03, 8.65530968e-03],\n",
              "       [6.85811043e-04, 5.63001633e-03, 5.24818897e-03],\n",
              "       [8.41951370e-03, 2.67744064e-04, 3.24261189e-03],\n",
              "       [1.13165379e-02, 6.60169125e-03, 3.11636925e-03],\n",
              "       [3.22914124e-03, 5.22494316e-04, 3.39126587e-03],\n",
              "       [1.08218193e-03, 5.42891026e-03, 6.99937344e-03],\n",
              "       [1.01716518e-02, 2.01742649e-02, 1.65936947e-02],\n",
              "       [3.80086899e-03, 8.89241695e-03, 4.31442261e-03],\n",
              "       [1.06060505e-03, 1.68144703e-03, 2.00390816e-03],\n",
              "       [4.29272652e-04, 4.93001938e-03, 7.03668594e-03],\n",
              "       [1.19411945e-03, 6.44671917e-03, 2.55346298e-03],\n",
              "       [8.68368149e-03, 6.68466091e-03, 4.59897518e-03],\n",
              "       [3.02791595e-03, 2.57384777e-03, 1.49726868e-04],\n",
              "       [2.67159939e-03, 5.44548035e-04, 3.58617306e-03],\n",
              "       [1.04653835e-03, 9.36806202e-03, 7.15804100e-03],\n",
              "       [1.84965134e-03, 1.60002708e-03, 6.46615028e-03],\n",
              "       [7.76398182e-03, 1.13271475e-02, 4.63020802e-03],\n",
              "       [2.38418579e-07, 1.45566463e-03, 1.03521347e-03],\n",
              "       [1.15990639e-02, 1.17707253e-03, 1.32203102e-03],\n",
              "       [8.25285912e-04, 2.70974636e-03, 1.72877312e-03],\n",
              "       [8.60297680e-03, 1.16956234e-03, 6.08301163e-03],\n",
              "       [9.31227207e-03, 7.15255737e-06, 1.73664093e-02],\n",
              "       [1.00798607e-02, 8.41677189e-03, 1.83725357e-03],\n",
              "       [4.17780876e-03, 6.03675842e-04, 1.17433071e-03],\n",
              "       [7.38739967e-04, 4.43661213e-03, 6.89625740e-04],\n",
              "       [2.13229656e-03, 3.95476818e-03, 1.81680918e-02],\n",
              "       [1.10626221e-04, 7.02142715e-04, 2.79068947e-03]], dtype=float32)>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. Find the min values of the tensor you created in 6 along the first axis.\n",
        "tf.reduce_min(tensor_3, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 3), dtype=float32, numpy=\n",
              "array([[0.99845374, 0.99930906, 0.99262166],\n",
              "       [0.99466574, 0.99434555, 0.9957906 ],\n",
              "       [0.9993377 , 0.9988344 , 0.99788725],\n",
              "       [0.9930023 , 0.99388456, 0.9973532 ],\n",
              "       [0.99890304, 0.99934196, 0.999063  ],\n",
              "       [0.99909663, 0.9912498 , 0.9989666 ],\n",
              "       [0.9984517 , 0.9993125 , 0.9972266 ],\n",
              "       [0.9851161 , 0.9997518 , 0.9938358 ],\n",
              "       [0.99558496, 0.9875896 , 0.99800336],\n",
              "       [0.99865353, 0.9981276 , 0.99659836],\n",
              "       [0.99160516, 0.99429524, 0.99986553],\n",
              "       [0.99120665, 0.9974369 , 0.9837067 ],\n",
              "       [0.9998193 , 0.9986278 , 0.9997519 ],\n",
              "       [0.9990151 , 0.9997431 , 0.99959373],\n",
              "       [0.99833953, 0.99908006, 0.9974154 ],\n",
              "       [0.9997325 , 0.9948616 , 0.99942064],\n",
              "       [0.9960431 , 0.99533176, 0.99374545],\n",
              "       [0.99750674, 0.9957348 , 0.99729204],\n",
              "       [0.9953059 , 0.99919796, 0.99888754],\n",
              "       [0.99667954, 0.9962187 , 0.99953544],\n",
              "       [0.9983853 , 0.9915079 , 0.99962735],\n",
              "       [0.9898201 , 0.99667823, 0.99680734],\n",
              "       [0.99451494, 0.9982387 , 0.9974679 ],\n",
              "       [0.99928916, 0.99623907, 0.9949752 ],\n",
              "       [0.99431205, 0.99085116, 0.9984652 ],\n",
              "       [0.9947418 , 0.99655926, 0.99838555],\n",
              "       [0.9961513 , 0.99756706, 0.99831486],\n",
              "       [0.99408686, 0.99626756, 0.9995775 ],\n",
              "       [0.99727106, 0.9978094 , 0.9874866 ],\n",
              "       [0.99634314, 0.9921826 , 0.99808526],\n",
              "       [0.9964644 , 0.99127257, 0.98901904],\n",
              "       [0.9985864 , 0.9894761 , 0.9985472 ],\n",
              "       [0.9973928 , 0.9987302 , 0.98841095],\n",
              "       [0.99437606, 0.9983698 , 0.9973351 ],\n",
              "       [0.9954928 , 0.9996017 , 0.99777126],\n",
              "       [0.9840361 , 0.99596083, 0.9972894 ],\n",
              "       [0.99978673, 0.9843577 , 0.99390256],\n",
              "       [0.9986249 , 0.9794526 , 0.9955791 ],\n",
              "       [0.9995458 , 0.99456394, 0.9946526 ],\n",
              "       [0.9991182 , 0.9961295 , 0.9953816 ],\n",
              "       [0.99541664, 0.99530363, 0.99985814],\n",
              "       [0.99263835, 0.999109  , 0.9969249 ],\n",
              "       [0.9991859 , 0.99065435, 0.9914136 ],\n",
              "       [0.9906702 , 0.99452376, 0.9996517 ],\n",
              "       [0.9975053 , 0.9897255 , 0.9887798 ],\n",
              "       [0.98918223, 0.9960978 , 0.99724174],\n",
              "       [0.9943588 , 0.99851537, 0.99697995],\n",
              "       [0.9967083 , 0.9982369 , 0.997609  ],\n",
              "       [0.9994606 , 0.99846065, 0.99079216],\n",
              "       [0.9987831 , 0.997278  , 0.987236  ],\n",
              "       [0.99959457, 0.99533796, 0.99766517],\n",
              "       [0.9996768 , 0.9908546 , 0.9958056 ],\n",
              "       [0.9995378 , 0.9937458 , 0.9895203 ],\n",
              "       [0.9995246 , 0.98839176, 0.99309456],\n",
              "       [0.996156  , 0.9999633 , 0.99291325],\n",
              "       [0.98664284, 0.9909704 , 0.9921967 ],\n",
              "       [0.9984081 , 0.9997122 , 0.9923812 ],\n",
              "       [0.9954152 , 0.99256027, 0.9987396 ],\n",
              "       [0.98873234, 0.9999918 , 0.99861574],\n",
              "       [0.99961996, 0.9944428 , 0.988245  ],\n",
              "       [0.9999813 , 0.9896165 , 0.99895644],\n",
              "       [0.9984187 , 0.993991  , 0.9873296 ],\n",
              "       [0.9995934 , 0.999403  , 0.9984983 ],\n",
              "       [0.9975642 , 0.99994886, 0.9953469 ],\n",
              "       [0.9973607 , 0.99998367, 0.99608755],\n",
              "       [0.99653447, 0.9945427 , 0.9993334 ],\n",
              "       [0.999442  , 0.9982531 , 0.9984993 ],\n",
              "       [0.9896691 , 0.9993751 , 0.99601614],\n",
              "       [0.9977627 , 0.9980459 , 0.9989507 ],\n",
              "       [0.9988378 , 0.99818516, 0.9969574 ],\n",
              "       [0.9970051 , 0.98135674, 0.9989995 ],\n",
              "       [0.9956008 , 0.9917606 , 0.9979981 ],\n",
              "       [0.9976326 , 0.9963504 , 0.996541  ],\n",
              "       [0.99753976, 0.99978006, 0.9881561 ],\n",
              "       [0.99982166, 0.9932102 , 0.99769175],\n",
              "       [0.99821615, 0.99675095, 0.9987265 ],\n",
              "       [0.9968225 , 0.99175334, 0.9970671 ],\n",
              "       [0.9992144 , 0.9929007 , 0.9995568 ],\n",
              "       [0.99542606, 0.9955307 , 0.9950546 ],\n",
              "       [0.9912801 , 0.9920186 , 0.99956656],\n",
              "       [0.99543405, 0.997826  , 0.99751556],\n",
              "       [0.99896955, 0.99907005, 0.9950589 ],\n",
              "       [0.9938457 , 0.9924774 , 0.9877428 ],\n",
              "       [0.99976754, 0.99726427, 0.99843144],\n",
              "       [0.9922346 , 0.9969646 , 0.9881915 ],\n",
              "       [0.9937842 , 0.9972644 , 0.9998956 ],\n",
              "       [0.99693096, 0.99574876, 0.99912345],\n",
              "       [0.9993086 , 0.99804485, 0.9992548 ],\n",
              "       [0.9941571 , 0.99510634, 0.9946796 ],\n",
              "       [0.9945396 , 0.99862957, 0.9913138 ],\n",
              "       [0.9989486 , 0.9986596 , 0.9986067 ],\n",
              "       [0.986789  , 0.99811435, 0.99629354],\n",
              "       [0.9989364 , 0.9997182 , 0.9935856 ],\n",
              "       [0.99844515, 0.9904369 , 0.99422824],\n",
              "       [0.9975085 , 0.9815272 , 0.9923638 ],\n",
              "       [0.99994373, 0.99456024, 0.9711864 ],\n",
              "       [0.98979545, 0.9959949 , 0.9955597 ],\n",
              "       [0.99104965, 0.9973923 , 0.99806154],\n",
              "       [0.99176776, 0.99783957, 0.9935384 ],\n",
              "       [0.9991542 , 0.9995054 , 0.9986594 ],\n",
              "       [0.9993583 , 0.9997277 , 0.99733853],\n",
              "       [0.9923755 , 0.9999565 , 0.9982939 ],\n",
              "       [0.99940395, 0.9925839 , 0.9935405 ],\n",
              "       [0.99648416, 0.99523413, 0.99860036],\n",
              "       [0.99767065, 0.9898715 , 0.99171114],\n",
              "       [0.990672  , 0.99445784, 0.99540615],\n",
              "       [0.9997612 , 0.988111  , 0.99611986],\n",
              "       [0.9969163 , 0.9981903 , 0.9816766 ],\n",
              "       [0.9918184 , 0.99933934, 0.99705124],\n",
              "       [0.99425507, 0.996145  , 0.983436  ],\n",
              "       [0.9985815 , 0.998348  , 0.99590385],\n",
              "       [0.992785  , 0.99797094, 0.99329996],\n",
              "       [0.99191403, 0.9929569 , 0.999544  ],\n",
              "       [0.9920981 , 0.9982209 , 0.9972125 ],\n",
              "       [0.9937252 , 0.976534  , 0.9985924 ],\n",
              "       [0.99809015, 0.9988475 , 0.9993112 ],\n",
              "       [0.99380183, 0.99764264, 0.9950968 ],\n",
              "       [0.9922925 , 0.9976479 , 0.99740744],\n",
              "       [0.9970808 , 0.9934089 , 0.9996041 ],\n",
              "       [0.99001837, 0.99824405, 0.9996246 ],\n",
              "       [0.9972919 , 0.9996153 , 0.99104655],\n",
              "       [0.99976707, 0.99481034, 0.99427116],\n",
              "       [0.9981848 , 0.9992788 , 0.99683976],\n",
              "       [0.9877726 , 0.9963125 , 0.9961529 ],\n",
              "       [0.99979734, 0.9868486 , 0.99988794],\n",
              "       [0.99378014, 0.9875746 , 0.9965    ],\n",
              "       [0.9991933 , 0.9995012 , 0.9985533 ],\n",
              "       [0.9789599 , 0.9967655 , 0.9953743 ],\n",
              "       [0.99894893, 0.9932231 , 0.996881  ],\n",
              "       [0.9859452 , 0.99585104, 0.9945197 ],\n",
              "       [0.9956863 , 0.98131907, 0.9989102 ],\n",
              "       [0.99313366, 0.999333  , 0.9984505 ],\n",
              "       [0.99984443, 0.995026  , 0.9985832 ],\n",
              "       [0.99807906, 0.99322903, 0.99854994],\n",
              "       [0.97891176, 0.9948453 , 0.98883545],\n",
              "       [0.9987898 , 0.9978037 , 0.999081  ],\n",
              "       [0.9970453 , 0.9867351 , 0.99888015],\n",
              "       [0.9949591 , 0.9995016 , 0.99157906],\n",
              "       [0.99813557, 0.9934578 , 0.99707806],\n",
              "       [0.9887134 , 0.99530876, 0.9906883 ],\n",
              "       [0.9998046 , 0.99942315, 0.99975836],\n",
              "       [0.9979677 , 0.9975052 , 0.9999776 ],\n",
              "       [0.9999778 , 0.99488246, 0.997661  ],\n",
              "       [0.99275684, 0.99993813, 0.9913701 ],\n",
              "       [0.99626017, 0.9990027 , 0.99823654],\n",
              "       [0.9963701 , 0.9957473 , 0.9917549 ],\n",
              "       [0.99672043, 0.9957856 , 0.99390566],\n",
              "       [0.9960207 , 0.9996743 , 0.9989439 ],\n",
              "       [0.9993167 , 0.99104536, 0.998296  ],\n",
              "       [0.99649525, 0.99682474, 0.9954903 ],\n",
              "       [0.99623704, 0.99972606, 0.982044  ],\n",
              "       [0.9953575 , 0.99743235, 0.99541306],\n",
              "       [0.9937023 , 0.99967074, 0.99557424],\n",
              "       [0.9903748 , 0.9969835 , 0.9999696 ],\n",
              "       [0.99955475, 0.9985409 , 0.99353635],\n",
              "       [0.99534845, 0.9961895 , 0.99907935],\n",
              "       [0.9991518 , 0.9878471 , 0.9969382 ],\n",
              "       [0.9981859 , 0.9993571 , 0.9950347 ],\n",
              "       [0.9946494 , 0.99151003, 0.9954426 ],\n",
              "       [0.99834955, 0.9994116 , 0.9969311 ],\n",
              "       [0.99342704, 0.99901116, 0.9950397 ],\n",
              "       [0.9958389 , 0.99755883, 0.9965949 ],\n",
              "       [0.9910518 , 0.99429166, 0.9937006 ],\n",
              "       [0.99318564, 0.99626637, 0.9909122 ],\n",
              "       [0.9969504 , 0.9995512 , 0.9927335 ],\n",
              "       [0.99350166, 0.99825716, 0.99512136],\n",
              "       [0.99385047, 0.99633026, 0.988605  ],\n",
              "       [0.9947401 , 0.9994103 , 0.9984137 ],\n",
              "       [0.9988979 , 0.9962628 , 0.988258  ],\n",
              "       [0.9974605 , 0.9941627 , 0.9996201 ],\n",
              "       [0.99603176, 0.999653  , 0.99351084],\n",
              "       [0.9949826 , 0.99009144, 0.9872658 ],\n",
              "       [0.99648154, 0.9907197 , 0.9891151 ],\n",
              "       [0.9922403 , 0.98299015, 0.9996239 ],\n",
              "       [0.99772525, 0.99938893, 0.99636126],\n",
              "       [0.99716914, 0.9977088 , 0.9889859 ],\n",
              "       [0.99845135, 0.9934511 , 0.99096704],\n",
              "       [0.9931505 , 0.9987241 , 0.99772716],\n",
              "       [0.9976144 , 0.9947636 , 0.9921236 ],\n",
              "       [0.9916476 , 0.98612094, 0.9861163 ],\n",
              "       [0.9959618 , 0.993968  , 0.99612   ],\n",
              "       [0.9948534 , 0.9978998 , 0.99381113],\n",
              "       [0.99554586, 0.9999758 , 0.98724246],\n",
              "       [0.99526   , 0.9965458 , 0.99523306],\n",
              "       [0.99893606, 0.9995725 , 0.9637047 ],\n",
              "       [0.9996016 , 0.9939934 , 0.99906206],\n",
              "       [0.99498045, 0.9996003 , 0.9912348 ],\n",
              "       [0.9999355 , 0.9930407 , 0.99241006],\n",
              "       [0.99889994, 0.99980307, 0.9970739 ],\n",
              "       [0.9966061 , 0.99821866, 0.99702716],\n",
              "       [0.9993744 , 0.9981735 , 0.99704874],\n",
              "       [0.99622035, 0.98396575, 0.9986981 ],\n",
              "       [0.99479496, 0.9976603 , 0.98908913],\n",
              "       [0.9896605 , 0.9883368 , 0.99734986],\n",
              "       [0.9965801 , 0.99859524, 0.9994631 ],\n",
              "       [0.9929483 , 0.99824667, 0.9972844 ],\n",
              "       [0.9988158 , 0.9944594 , 0.9974779 ],\n",
              "       [0.9900675 , 0.98776937, 0.9794773 ],\n",
              "       [0.9920641 , 0.9933765 , 0.99284697],\n",
              "       [0.97483206, 0.9896858 , 0.99785244],\n",
              "       [0.99169624, 0.99616754, 0.99581194],\n",
              "       [0.995168  , 0.9992075 , 0.9958538 ],\n",
              "       [0.9823456 , 0.99882615, 0.99941003],\n",
              "       [0.9962709 , 0.9976268 , 0.9993137 ],\n",
              "       [0.999177  , 0.9978261 , 0.9963287 ],\n",
              "       [0.9993247 , 0.9994161 , 0.9961573 ],\n",
              "       [0.9955872 , 0.99744296, 0.985942  ],\n",
              "       [0.99905825, 0.9956869 , 0.97578764],\n",
              "       [0.9917282 , 0.9934075 , 0.99499476],\n",
              "       [0.9978045 , 0.9988322 , 0.9970828 ],\n",
              "       [0.99708235, 0.98827505, 0.99435806],\n",
              "       [0.9978682 , 0.9953898 , 0.99409115],\n",
              "       [0.99955773, 0.99519396, 0.9965714 ],\n",
              "       [0.9985641 , 0.9922924 , 0.99848807],\n",
              "       [0.9997562 , 0.9976785 , 0.9992213 ],\n",
              "       [0.99955356, 0.9928005 , 0.9997659 ],\n",
              "       [0.999061  , 0.9985033 , 0.9969462 ],\n",
              "       [0.9990126 , 0.99750376, 0.997612  ],\n",
              "       [0.9974495 , 0.99788094, 0.9966214 ],\n",
              "       [0.9992498 , 0.99883103, 0.9920347 ],\n",
              "       [0.9967823 , 0.9995347 , 0.9976599 ],\n",
              "       [0.99361277, 0.99625194, 0.9966253 ],\n",
              "       [0.9970275 , 0.99856126, 0.9946816 ],\n",
              "       [0.9994445 , 0.99884284, 0.991447  ]], dtype=float32)>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. Find the min values of the tensor you created in 6 along the first axis.\n",
        "tf.reduce_max(tensor_3, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
              "array([[[[8.0315602e-01, 4.9777734e-01, 3.7054038e-01],\n",
              "         [9.1186738e-01, 6.3764203e-01, 1.8209696e-01],\n",
              "         [6.3791955e-01, 2.7701473e-01, 4.2271137e-02],\n",
              "         ...,\n",
              "         [1.0830712e-01, 4.5979273e-01, 2.5716281e-01],\n",
              "         [8.7138689e-01, 1.8434000e-01, 4.4757760e-01],\n",
              "         [7.4110627e-02, 9.0852141e-01, 5.3693414e-01]],\n",
              "\n",
              "        [[5.5596435e-01, 6.8776274e-01, 7.6051474e-02],\n",
              "         [1.6737962e-01, 7.1785092e-01, 2.7642274e-01],\n",
              "         [2.6995218e-01, 3.2203627e-01, 8.8224900e-01],\n",
              "         ...,\n",
              "         [4.8168826e-01, 5.0150025e-01, 8.6756039e-01],\n",
              "         [4.1261053e-01, 1.2770486e-01, 5.8186901e-01],\n",
              "         [2.5495613e-01, 3.9036548e-01, 9.8529553e-01]],\n",
              "\n",
              "        [[8.0935180e-01, 1.9740558e-01, 3.5899937e-01],\n",
              "         [1.1216915e-01, 9.1016293e-04, 3.6382091e-01],\n",
              "         [5.1202202e-01, 3.9188230e-01, 8.8335538e-01],\n",
              "         ...,\n",
              "         [2.0133841e-01, 9.1663551e-01, 1.9890130e-01],\n",
              "         [8.0388057e-01, 3.9227080e-01, 2.9688942e-01],\n",
              "         [8.9319050e-01, 2.9692888e-01, 2.6492047e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[7.3653197e-01, 5.9242892e-01, 8.1022096e-01],\n",
              "         [3.2385099e-01, 9.4225824e-01, 8.4279275e-01],\n",
              "         [5.2548873e-01, 8.8999271e-02, 1.2152910e-01],\n",
              "         ...,\n",
              "         [4.4721401e-01, 2.0952868e-01, 9.3782067e-02],\n",
              "         [5.1644707e-01, 7.4352753e-01, 7.4530303e-01],\n",
              "         [4.3693781e-03, 1.0793984e-01, 1.7783213e-01]],\n",
              "\n",
              "        [[7.6054347e-01, 8.0798697e-01, 3.9492905e-01],\n",
              "         [4.0577006e-01, 9.6265435e-02, 8.8253260e-01],\n",
              "         [6.7700970e-01, 7.8380144e-01, 9.3841922e-01],\n",
              "         ...,\n",
              "         [3.1409883e-01, 2.0651186e-01, 5.1043892e-01],\n",
              "         [6.6967010e-02, 3.1983531e-01, 7.4677360e-01],\n",
              "         [7.0548081e-01, 8.2629704e-01, 7.0540214e-01]],\n",
              "\n",
              "        [[6.4126742e-01, 5.8223104e-01, 5.1815867e-02],\n",
              "         [6.2203467e-01, 5.7224095e-01, 9.0543139e-01],\n",
              "         [9.6411026e-01, 2.6061213e-01, 7.4845552e-02],\n",
              "         ...,\n",
              "         [5.8922923e-01, 1.2655807e-01, 7.0523393e-01],\n",
              "         [9.5485377e-01, 6.6495812e-01, 6.4105380e-01],\n",
              "         [4.4474745e-01, 9.7424459e-01, 9.1788459e-01]]]], dtype=float32)>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 8. Create a tensor with random values of shape [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
        "tensor_4 = tf.random.uniform(shape=[1, 224, 224, 3])\n",
        "tensor_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[8.0315602e-01, 4.9777734e-01, 3.7054038e-01],\n",
              "        [9.1186738e-01, 6.3764203e-01, 1.8209696e-01],\n",
              "        [6.3791955e-01, 2.7701473e-01, 4.2271137e-02],\n",
              "        ...,\n",
              "        [1.0830712e-01, 4.5979273e-01, 2.5716281e-01],\n",
              "        [8.7138689e-01, 1.8434000e-01, 4.4757760e-01],\n",
              "        [7.4110627e-02, 9.0852141e-01, 5.3693414e-01]],\n",
              "\n",
              "       [[5.5596435e-01, 6.8776274e-01, 7.6051474e-02],\n",
              "        [1.6737962e-01, 7.1785092e-01, 2.7642274e-01],\n",
              "        [2.6995218e-01, 3.2203627e-01, 8.8224900e-01],\n",
              "        ...,\n",
              "        [4.8168826e-01, 5.0150025e-01, 8.6756039e-01],\n",
              "        [4.1261053e-01, 1.2770486e-01, 5.8186901e-01],\n",
              "        [2.5495613e-01, 3.9036548e-01, 9.8529553e-01]],\n",
              "\n",
              "       [[8.0935180e-01, 1.9740558e-01, 3.5899937e-01],\n",
              "        [1.1216915e-01, 9.1016293e-04, 3.6382091e-01],\n",
              "        [5.1202202e-01, 3.9188230e-01, 8.8335538e-01],\n",
              "        ...,\n",
              "        [2.0133841e-01, 9.1663551e-01, 1.9890130e-01],\n",
              "        [8.0388057e-01, 3.9227080e-01, 2.9688942e-01],\n",
              "        [8.9319050e-01, 2.9692888e-01, 2.6492047e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[7.3653197e-01, 5.9242892e-01, 8.1022096e-01],\n",
              "        [3.2385099e-01, 9.4225824e-01, 8.4279275e-01],\n",
              "        [5.2548873e-01, 8.8999271e-02, 1.2152910e-01],\n",
              "        ...,\n",
              "        [4.4721401e-01, 2.0952868e-01, 9.3782067e-02],\n",
              "        [5.1644707e-01, 7.4352753e-01, 7.4530303e-01],\n",
              "        [4.3693781e-03, 1.0793984e-01, 1.7783213e-01]],\n",
              "\n",
              "       [[7.6054347e-01, 8.0798697e-01, 3.9492905e-01],\n",
              "        [4.0577006e-01, 9.6265435e-02, 8.8253260e-01],\n",
              "        [6.7700970e-01, 7.8380144e-01, 9.3841922e-01],\n",
              "        ...,\n",
              "        [3.1409883e-01, 2.0651186e-01, 5.1043892e-01],\n",
              "        [6.6967010e-02, 3.1983531e-01, 7.4677360e-01],\n",
              "        [7.0548081e-01, 8.2629704e-01, 7.0540214e-01]],\n",
              "\n",
              "       [[6.4126742e-01, 5.8223104e-01, 5.1815867e-02],\n",
              "        [6.2203467e-01, 5.7224095e-01, 9.0543139e-01],\n",
              "        [9.6411026e-01, 2.6061213e-01, 7.4845552e-02],\n",
              "        ...,\n",
              "        [5.8922923e-01, 1.2655807e-01, 7.0523393e-01],\n",
              "        [9.5485377e-01, 6.6495812e-01, 6.4105380e-01],\n",
              "        [4.4474745e-01, 9.7424459e-01, 9.1788459e-01]]], dtype=float32)>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_4_squeezed = tf.squeeze(tensor_4)\n",
        "tensor_4_squeezed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=9>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 9. Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.\n",
        "tensor_5 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "tf.argmax(tensor_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 10. One-hot encode the tensor you created in 9.\n",
        "tf.one_hot(tensor_5, depth=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
