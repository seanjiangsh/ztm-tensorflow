{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac43dcb",
   "metadata": {},
   "source": [
    "# 09. Milestone Project 2: SkimLit ðŸ“„ðŸ”¥\n",
    "\n",
    "In the previous notebook ([NLP fundamentals in TensorFlow](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb)), we went through some fundamental natural lanuage processing concepts. The main ones being **tokenzation** (turning words into numbers) and **creating embeddings** (creating a numerical representation of words).\n",
    "\n",
    "In this project, we're going to be putting what we've learned into practice.\n",
    "\n",
    "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [*PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071).\n",
    "\n",
    "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
    "\n",
    "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
    "\n",
    "In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
    "\n",
    "![Skimlit example inputs and outputs](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-skimlit-overview-input-and-output.png)\n",
    "\n",
    "*Example inputs ([harder to read abstract from PubMed](https://pubmed.ncbi.nlm.nih.gov/28942748/)) and outputs ([easier to read abstract](https://pubmed.ncbi.nlm.nih.gov/32537182/)) of the model we're going to build. The model will take an abstract wall of text and predict the section label each sentence should have.*  \n",
    "\n",
    "### Model Input\n",
    "\n",
    "For example, can we train an NLP model which takes the following input (note: the following sample has had all numerical symbols replaced with \"@\"):\n",
    "\n",
    "> To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ).\n",
    "Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ).,\n",
    "Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured.\n",
    "There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ).\n",
    "\n",
    "### Model output\n",
    "\n",
    "And returns the following output:\n",
    "\n",
    "```\n",
    "['###24293578\\n',\n",
    " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
    " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
    " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
    " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
    " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
    " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
    " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
    " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
    " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
    " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
    " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
    " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
    " '\\n']\n",
    " ```\n",
    "\n",
    "### Problem in a sentence\n",
    "\n",
    "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature. \n",
    "\n",
    "### Solution in a sentence\n",
    "\n",
    "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc)  to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.\n",
    "\n",
    "> ðŸ“– **Resources:** Before going through the code in this notebook, you might want to get a background of what we're going to be doing. To do so, spend an hour (or two) going through the following papers and then return to this notebook:\n",
    "1. Where our data is coming from: [*PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071)\n",
    "2. Where our model is coming from: [*Neural networks for joint sentence\n",
    "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
    "\n",
    "## What we're going to cover\n",
    "\n",
    "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
    "\n",
    "* Downloading a text dataset ([PubMed RCT200k from GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct))\n",
    "* Writing a preprocessing function to prepare our data for modelling\n",
    "* Setting up a series of modelling experiments\n",
    "  * Making a baseline (TF-IDF classifier)\n",
    "  * Deep models with different combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
    "* Building our first multimodal model (taking multiple types of data inputs)\n",
    "  * Replicating the model architecture from https://arxiv.org/abs/1612.05251\n",
    "* Find the most wrong predictions\n",
    "* Making predictions on PubMed abstracts from the wild\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1dae9",
   "metadata": {},
   "source": [
    "## Confirm access to a GPU\n",
    "\n",
    "Since we're going to be building deep learning models, let's make sure we have a GPU.\n",
    "\n",
    "In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
    "\n",
    "If you don't have access to a GPU, the models we're building here will likely take up to 10x longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eeea117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU (UUID: GPU-f2fc91ef-d4e3-c010-ebf9-2d38bc5874e8)\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ed039",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n",
    "\n",
    "In a phenomenal act of kindness, the authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files [on GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct).\n",
    "\n",
    "We can copy them to our local directory using `git clone https://github.com/Franck-Dernoncourt/pubmed-rct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d943154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed_200k_RCT\n",
      "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
      "PubMed_20k_RCT\n",
      "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "RCT_DIR = 'data/pubmed-rct/'\n",
    "!ls {RCT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8116645",
   "metadata": {},
   "source": [
    "Checking the contents of the downloaded repository, you can see there are four folders.\n",
    "\n",
    "Each contains a different version of the PubMed 200k RCT dataset.\n",
    "\n",
    "Looking at the [README file](https://github.com/Franck-Dernoncourt/pubmed-rct) from the GitHub page, we get the following information:\n",
    "* PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
    "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
    "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
    "\n",
    "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n",
    "\n",
    "Why this one?\n",
    "\n",
    "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with `@` but we didn't.\n",
    "\n",
    "Let's check the file contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb824cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt  test.txt  train.txt\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset \n",
    "!ls {RCT_DIR}PubMed_20k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b3196",
   "metadata": {},
   "source": [
    "Beautiful, looks like we've got three separate text files:\n",
    "* `train.txt` - training samples.\n",
    "* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n",
    "* `test.txt` - test samples.\n",
    "\n",
    "To save ourselves typing out the filepath to our target directory each time, let's turn it into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a427bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using the 20k dataset\n",
    "data_dir = RCT_DIR + \"PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb7413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995bb83",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Okay, now we've downloaded some text data, do you think we're ready to model it?\n",
    "\n",
    "Wait...\n",
    "\n",
    "We've downloaded the data but we haven't even looked at it yet.\n",
    "\n",
    "What's the motto for getting familiar with any new dataset?\n",
    "\n",
    "I'll give you a clue, the word begins with \"v\" and we say it three times.\n",
    "\n",
    "> Vibe, vibe, vibe?\n",
    "\n",
    "Sort of... we've definitely got to the feel the vibe of our data.\n",
    "\n",
    "> Values, values, values?\n",
    "\n",
    "Right again, we want to *see* lots of values but not quite what we're looking for.\n",
    "\n",
    "> Visualize, visualize, visualize?\n",
    "\n",
    "Boom! That's it. To get familiar and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n",
    "\n",
    "Because our data is in the form of text files, let's write some code to read each of the lines in a target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0ae796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "  Reads filename (a text file) and returns the lines of text as a list.\n",
    "  \n",
    "  Args:\n",
    "      filename: a string containing the target filepath to read.\n",
    "  \n",
    "  Returns:\n",
    "      A list of strings with one string per line from the target filename.\n",
    "      For example:\n",
    "      [\"this is the first line of filename\",\n",
    "       \"this is the second line of filename\",\n",
    "       \"...\"]\n",
    "  \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f5b44",
   "metadata": {},
   "source": [
    "Alright, we've got a little function, `get_lines()` which takes the filepath of a text file, opens it, reads each of the lines and returns them.\n",
    "\n",
    "Let's try it out on the training data (`train.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25dbde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = get_lines(data_dir + \"train.txt\")\n",
    "train_lines[:20]  # the whole first example of an abstract + a little more of the next one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dffdb4",
   "metadata": {},
   "source": [
    "Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n",
    "\n",
    "The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n",
    "\n",
    "Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n",
    "\n",
    "Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine learning model.\n",
    "\n",
    "Let's write a function to perform the following steps:\n",
    "* Take a target file of abstract samples.\n",
    "* Read the lines in the target file.\n",
    "* For each line in the target file:  \n",
    "  * If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n",
    "    * Keep count of the number of lines in a sample.\n",
    "  * If the line begins with `\\n` mark it as the end of an abstract sample.\n",
    "    * Keep count of the total lines in a sample.\n",
    "  * Record the text before the `\\t` as the label of the line.\n",
    "  * Record the text after the `\\t` as the text of the line.\n",
    "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
    "  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n",
    "  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n",
    "  * `\"text\"` - the text of the line in the abstract.\n",
    "  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n",
    "* Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
    "\n",
    "Example returned preprocessed sample (a single line from an abstract):\n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "  'target': 'OBJECTIVE',\n",
    "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
    "  'total_lines': 11},\n",
    "  ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c4ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence number\n",
    "  the target line is.\n",
    "\n",
    "  Args:\n",
    "      filename: a string of the target text file to read and extract line data\n",
    "      from.\n",
    "\n",
    "  Returns:\n",
    "      A list of dictionaries each containing a line from an abstract,\n",
    "      the lines label, the lines position in the abstract and the total number\n",
    "      of lines in the abstract where the line is from. For example:\n",
    "\n",
    "      [{\"target\": 'CONCLUSION',\n",
    "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
    "        \"line_number\": 8,\n",
    "        \"total_lines\": 8}]\n",
    "  \"\"\"\n",
    "    input_lines = get_lines(filename)  # get all lines from filename\n",
    "    abstract_lines = \"\"  # create an empty abstract\n",
    "    abstract_samples = []  # create an empty list of abstracts\n",
    "\n",
    "    # Loop through each line in target file\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"):  # check to see if line is an ID line\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\"  # reset abstract string\n",
    "        elif line.isspace():  # check to see if line is a new line\n",
    "            abstract_line_split = abstract_lines.splitlines()  # split abstract into separate lines\n",
    "\n",
    "            # Iterate through each line in abstract and count them at the same time\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {}  # create empty dict to store data from line\n",
    "                target_text_split = abstract_line.split(\"\\t\")  # split target label from text\n",
    "                line_data[\"target\"] = target_text_split[0]  # get target label\n",
    "                line_data[\"text\"] = target_text_split[1].lower()  # get target text and lower it\n",
    "                line_data[\"line_number\"] = abstract_line_number  # what number line does the line appear in the abstract?\n",
    "                line_data[\"total_lines\"] = len(abstract_line_split) - 1  # how many total lines are in the abstract? (start from 0)\n",
    "                abstract_samples.append(line_data)  # add line data to abstract samples list\n",
    "\n",
    "        else:  # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "            abstract_lines += line\n",
    "\n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf62efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.30 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Get data from file and preprocess it\n",
    "# Get data from file and preprocess it\n",
    "start_time = time.time()\n",
    "\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")  # dev is another name for validation set\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "\n",
    "print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "len(train_samples), len(val_samples), len(test_samples)\n",
    "\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")  # dev is another name for validation set\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e7128",
   "metadata": {},
   "source": [
    "How do our training samples look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f980636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:14]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
